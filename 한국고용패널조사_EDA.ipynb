{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM2qP2DP7wGE",
        "outputId": "830d6a79-f3b1-4795-8030-0c4ce9b157f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EX4Gfh87mgD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #dataframe을 다루는 library\n",
        "import matplotlib.pyplot #시각화 library\n",
        "import numpy as np #행렬연산 library\n",
        "from tqdm import tqdm #진행도 표시 library\n",
        "import warnings #경고 출력 관련 library\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_book=pd.read_csv('/content/drive/MyDrive/KEEPⅡ 1차년도 변수 레이아웃.csv')"
      ],
      "metadata": {
        "id": "fQcyCuAG71y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_book.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "lONipi1R74AU",
        "outputId": "d7d80179-ade6-4f64-a4eb-4fee261fcade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  <1차년도 한국교육고용패널2 LAYOUT>-학생\\n※ 학생 데이터의 담임평가 항목은 각 학생의 담임이 응답한 학생 평가임(담임 설문지 참조)  \\\n",
              "0                                             설문지 번호                               \n",
              "1                                                NaN                               \n",
              "2                                                NaN                               \n",
              "3                                                NaN                               \n",
              "4                                                NaN                               \n",
              "\n",
              "  Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \\\n",
              "0        변수명       변수설명        주관식       변수유형         측도         길이   \n",
              "1     Y16SID      학생 ID        NaN        숫자형         명목         12   \n",
              "2     Y16HID      가구 ID        NaN        숫자형         명목         10   \n",
              "3     Y16AID      교무 ID        NaN        숫자형         명목         12   \n",
              "4     Y16TID      담임 ID        NaN        숫자형         명목         12   \n",
              "\n",
              "  Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10  \n",
              "0          열    소수점이하자리       보기설명          비고  \n",
              "1       1-12          0        NaN         NaN  \n",
              "2      13-22          0        NaN         NaN  \n",
              "3      23-34          0        NaN         NaN  \n",
              "4      35-46          0        NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83f6b40a-589c-495f-9f4b-64f722649f6f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&lt;1차년도 한국교육고용패널2 LAYOUT&gt;-학생\\n※ 학생 데이터의 담임평가 항목은 각 학생의 담임이 응답한 학생 평가임(담임 설문지 참조)</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "      <th>Unnamed: 8</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>설문지 번호</td>\n",
              "      <td>변수명</td>\n",
              "      <td>변수설명</td>\n",
              "      <td>주관식</td>\n",
              "      <td>변수유형</td>\n",
              "      <td>측도</td>\n",
              "      <td>길이</td>\n",
              "      <td>열</td>\n",
              "      <td>소수점이하자리</td>\n",
              "      <td>보기설명</td>\n",
              "      <td>비고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Y16SID</td>\n",
              "      <td>학생 ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>숫자형</td>\n",
              "      <td>명목</td>\n",
              "      <td>12</td>\n",
              "      <td>1-12</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Y16HID</td>\n",
              "      <td>가구 ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>숫자형</td>\n",
              "      <td>명목</td>\n",
              "      <td>10</td>\n",
              "      <td>13-22</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Y16AID</td>\n",
              "      <td>교무 ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>숫자형</td>\n",
              "      <td>명목</td>\n",
              "      <td>12</td>\n",
              "      <td>23-34</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Y16TID</td>\n",
              "      <td>담임 ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>숫자형</td>\n",
              "      <td>명목</td>\n",
              "      <td>12</td>\n",
              "      <td>35-46</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83f6b40a-589c-495f-9f4b-64f722649f6f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83f6b40a-589c-495f-9f4b-64f722649f6f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83f6b40a-589c-495f-9f4b-64f722649f6f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_book.columns=code_book.iloc[0].tolist()\n",
        "code_book=code_book.drop([0],axis=0)"
      ],
      "metadata": {
        "id": "ExOKxedi8Ez2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_book.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yjO-7Mio89me",
        "outputId": "67d30563-85c2-40de-b241-a036b0e62304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  설문지 번호     변수명   변수설명  주관식 변수유형  측도  길이      열 소수점이하자리          보기설명   비고\n",
              "1    NaN  Y16SID  학생 ID  NaN  숫자형  명목  12   1-12       0           NaN  NaN\n",
              "2    NaN  Y16HID  가구 ID  NaN  숫자형  명목  10  13-22       0           NaN  NaN\n",
              "3    NaN  Y16AID  교무 ID  NaN  숫자형  명목  12  23-34       0           NaN  NaN\n",
              "4    NaN  Y16TID  담임 ID  NaN  숫자형  명목  12  35-46       0           NaN  NaN\n",
              "5    NaN  GENDER     성별  NaN  숫자형  명목   4  47-50       0  1=남자\\r\\n2=여자  NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e390caca-d471-4901-8d3e-2c55236190d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>설문지 번호</th>\n",
              "      <th>변수명</th>\n",
              "      <th>변수설명</th>\n",
              "      <th>주관식</th>\n",
              "      <th>변수유형</th>\n",
              "      <th>측도</th>\n",
              "      <th>길이</th>\n",
              "      <th>열</th>\n",
              "      <th>소수점이하자리</th>\n",
              "      <th>보기설명</th>\n",
              "      <th>비고</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Y16SID</td>\n",
              "      <td>학생 ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>숫자형</td>\n",
              "      <td>명목</td>\n",
              "      <td>12</td>\n",
              "      <td>1-12</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Y16HID</td>\n",
              "      <td>가구 ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>숫자형</td>\n",
              "      <td>명목</td>\n",
              "      <td>10</td>\n",
              "      <td>13-22</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Y16AID</td>\n",
              "      <td>교무 ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>숫자형</td>\n",
              "      <td>명목</td>\n",
              "      <td>12</td>\n",
              "      <td>23-34</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Y16TID</td>\n",
              "      <td>담임 ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>숫자형</td>\n",
              "      <td>명목</td>\n",
              "      <td>12</td>\n",
              "      <td>35-46</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>GENDER</td>\n",
              "      <td>성별</td>\n",
              "      <td>NaN</td>\n",
              "      <td>숫자형</td>\n",
              "      <td>명목</td>\n",
              "      <td>4</td>\n",
              "      <td>47-50</td>\n",
              "      <td>0</td>\n",
              "      <td>1=남자\\r\\n2=여자</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e390caca-d471-4901-8d3e-2c55236190d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e390caca-d471-4901-8d3e-2c55236190d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e390caca-d471-4901-8d3e-2c55236190d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/KEEPⅡ 1차년도 학생.csv')"
      ],
      "metadata": {
        "id": "DKwGM9-M9H2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "LrCWw2BD9OAs",
        "outputId": "5e17f6d9-488f-41e8-def0-a9606dff748c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Y16SID      Y16HID  Y16AID   Y16TID  GENDER  Y16STYPE  LOCATION  \\\n",
              "0  111001101  1110011011  111001  1110011       2         1         1   \n",
              "1  111001102  1110011021  111001  1110011       2         1         1   \n",
              "2  111001103  1110011031  111001  1110011       2         1         1   \n",
              "3  111001104  1110011041  111001  1110011       2         1         1   \n",
              "4  111001201  1110012011  111001  1110012       2         1         1   \n",
              "\n",
              "   Y16S01001  Y16S01002  Y16S01003  ...  Y16T02021  Y16T02022  Y16T02023  \\\n",
              "0          1          1          9  ...          0          0          0   \n",
              "1          1          1          3  ...          0          0          0   \n",
              "2          1          1         -2  ...          0          0          0   \n",
              "3          1          3         -2  ...          0          1          0   \n",
              "4          1          1          6  ...          1          0          0   \n",
              "\n",
              "   Y16T02024  Y16T02025  Y16T02026  Y16T02027  Y16T02028  Y16T02029  \\\n",
              "0          0          0          5          2          2          2   \n",
              "1          0          0          3          2          2          2   \n",
              "2          0          0          7          2          1          2   \n",
              "3          0          0          6          1          1          2   \n",
              "4          0          0          1          2          2          2   \n",
              "\n",
              "   Y16_WEIGHT  \n",
              "0       61.54  \n",
              "1       61.54  \n",
              "2       61.54  \n",
              "3       61.54  \n",
              "4       61.54  \n",
              "\n",
              "[5 rows x 462 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a3cf11c-630f-4825-9d47-c73789fc2677\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y16SID</th>\n",
              "      <th>Y16HID</th>\n",
              "      <th>Y16AID</th>\n",
              "      <th>Y16TID</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>Y16STYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>Y16S01001</th>\n",
              "      <th>Y16S01002</th>\n",
              "      <th>Y16S01003</th>\n",
              "      <th>...</th>\n",
              "      <th>Y16T02021</th>\n",
              "      <th>Y16T02022</th>\n",
              "      <th>Y16T02023</th>\n",
              "      <th>Y16T02024</th>\n",
              "      <th>Y16T02025</th>\n",
              "      <th>Y16T02026</th>\n",
              "      <th>Y16T02027</th>\n",
              "      <th>Y16T02028</th>\n",
              "      <th>Y16T02029</th>\n",
              "      <th>Y16_WEIGHT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>111001101</td>\n",
              "      <td>1110011011</td>\n",
              "      <td>111001</td>\n",
              "      <td>1110011</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>61.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111001102</td>\n",
              "      <td>1110011021</td>\n",
              "      <td>111001</td>\n",
              "      <td>1110011</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>61.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>111001103</td>\n",
              "      <td>1110011031</td>\n",
              "      <td>111001</td>\n",
              "      <td>1110011</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>61.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>111001104</td>\n",
              "      <td>1110011041</td>\n",
              "      <td>111001</td>\n",
              "      <td>1110011</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>61.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>111001201</td>\n",
              "      <td>1110012011</td>\n",
              "      <td>111001</td>\n",
              "      <td>1110012</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>61.54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 462 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a3cf11c-630f-4825-9d47-c73789fc2677')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a3cf11c-630f-4825-9d47-c73789fc2677 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a3cf11c-630f-4825-9d47-c73789fc2677');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_book.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt5Be_LD9Va8",
        "outputId": "fbd45d17-8b63-4cbf-d1d6-e86314b6b1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(485, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns=code_book['변수설명'].tolist()[:462]"
      ],
      "metadata": {
        "id": "E3flKeP4-H38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "R-vOWt29-inS",
        "outputId": "a572bfe6-59bd-4cce-f541-9590c4db452c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       학생 ID       가구 ID   교무 ID    담임 ID  성별  학교유형  고등학교 소재지  재학 중인 고등학교 유형  \\\n",
              "0  111001101  1110011011  111001  1110011   2     1         1              1   \n",
              "1  111001102  1110011021  111001  1110011   2     1         1              1   \n",
              "2  111001103  1110011031  111001  1110011   2     1         1              1   \n",
              "3  111001104  1110011041  111001  1110011   2     1         1              1   \n",
              "4  111001201  1110012011  111001  1110012   2     1         1              1   \n",
              "\n",
              "   고등학교 계열  고등학교 계열 선택 이유  ...  (담임평가)교외 수상-학업  (담임평가)교외 수상-예체능  \\\n",
              "0        1              9  ...               0                0   \n",
              "1        1              3  ...               0                0   \n",
              "2        1             -2  ...               0                0   \n",
              "3        3             -2  ...               0                1   \n",
              "4        1              6  ...               1                0   \n",
              "\n",
              "   (담임평가)교외 수상-기능/기술  (담임평가)교외 수상-품행  (담임평가)교외 수상-기타  (담임평가)2학년 1학기 성적(등급)  \\\n",
              "0                  0               0               0                     5   \n",
              "1                  0               0               0                     3   \n",
              "2                  0               0               0                     7   \n",
              "3                  0               0               0                     6   \n",
              "4                  0               0               0                     1   \n",
              "\n",
              "   (담임평가)학업관련 학부모 상담 경험  (담임평가)생활 태도관련 학부모 상담 경험  (담임평가)진로 취업관련 학부모 상담 경험  \\\n",
              "0                     2                        2                        2   \n",
              "1                     2                        2                        2   \n",
              "2                     2                        1                        2   \n",
              "3                     1                        1                        2   \n",
              "4                     2                        2                        2   \n",
              "\n",
              "   학생 전체 가중치  \n",
              "0      61.54  \n",
              "1      61.54  \n",
              "2      61.54  \n",
              "3      61.54  \n",
              "4      61.54  \n",
              "\n",
              "[5 rows x 462 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a2dcd6a-f9f5-4916-880b-372b65a2d5e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>학생 ID</th>\n",
              "      <th>가구 ID</th>\n",
              "      <th>교무 ID</th>\n",
              "      <th>담임 ID</th>\n",
              "      <th>성별</th>\n",
              "      <th>학교유형</th>\n",
              "      <th>고등학교 소재지</th>\n",
              "      <th>재학 중인 고등학교 유형</th>\n",
              "      <th>고등학교 계열</th>\n",
              "      <th>고등학교 계열 선택 이유</th>\n",
              "      <th>...</th>\n",
              "      <th>(담임평가)교외 수상-학업</th>\n",
              "      <th>(담임평가)교외 수상-예체능</th>\n",
              "      <th>(담임평가)교외 수상-기능/기술</th>\n",
              "      <th>(담임평가)교외 수상-품행</th>\n",
              "      <th>(담임평가)교외 수상-기타</th>\n",
              "      <th>(담임평가)2학년 1학기 성적(등급)</th>\n",
              "      <th>(담임평가)학업관련 학부모 상담 경험</th>\n",
              "      <th>(담임평가)생활 태도관련 학부모 상담 경험</th>\n",
              "      <th>(담임평가)진로 취업관련 학부모 상담 경험</th>\n",
              "      <th>학생 전체 가중치</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>111001101</td>\n",
              "      <td>1110011011</td>\n",
              "      <td>111001</td>\n",
              "      <td>1110011</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>61.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111001102</td>\n",
              "      <td>1110011021</td>\n",
              "      <td>111001</td>\n",
              "      <td>1110011</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>61.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>111001103</td>\n",
              "      <td>1110011031</td>\n",
              "      <td>111001</td>\n",
              "      <td>1110011</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>61.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>111001104</td>\n",
              "      <td>1110011041</td>\n",
              "      <td>111001</td>\n",
              "      <td>1110011</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>61.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>111001201</td>\n",
              "      <td>1110012011</td>\n",
              "      <td>111001</td>\n",
              "      <td>1110012</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>61.54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 462 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a2dcd6a-f9f5-4916-880b-372b65a2d5e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a2dcd6a-f9f5-4916-880b-372b65a2d5e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a2dcd6a-f9f5-4916-880b-372b65a2d5e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMsKqFWwCh4t",
        "outputId": "78ee05f5-5edf-4fd8-bb1a-73b3be900135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 13 not upgraded.\n",
            "Need to get 9,599 kB of archives.\n",
            "After this operation, 29.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 fonts-nanum all 20180306-3 [9,599 kB]\n",
            "Fetched 9,599 kB in 0s (36.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20180306-3_all.deb ...\n",
            "Unpacking fonts-nanum (20180306-3) ...\n",
            "Setting up fonts-nanum (20180306-3) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ],
      "metadata": {
        "id": "aThSE0V3CsBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataprep.eda import create_report\n",
        "\n",
        "create_report(df)"
      ],
      "metadata": {
        "id": "Pd9U1UiB_qX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_eval=df.iloc[:,250:300]\n",
        "print(teacher_eval.shape)\n",
        "read=df.iloc[:,315]\n",
        "print(read.shape)\n",
        "df_1=pd.concat([teacher_eval, read],axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zmaphk_A2-1",
        "outputId": "9d86e81e-c122-4d53-c037-ba3d510da29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10558, 50)\n",
            "(10558,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr=df.corr(method='kendall')"
      ],
      "metadata": {
        "id": "jHdWvOMeGjoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#corr=df.corr() #상관관계 계산\n",
        "#print(corr['한달 평균 독서 권 수'])\n",
        "print(corr[corr['한달 평균 독서 권 수']>=0.2])\n",
        "#plt.figure(figsize=(40,40)) #그림 사이즈 조절\n",
        "#sns.heatmap(corr,annot=True) #히트맵 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HufQpykr-62D",
        "outputId": "619e13a5-a85d-4082-83cd-579707a9cd0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            학생 ID     가구 ID     교무 ID     담임 ID        성별  \\\n",
            "진로에 관한 생각과 태도-편견 및 고정관념 -0.067952 -0.068895 -0.067930 -0.067947  0.035508   \n",
            "혼자 공부하는 시간-주말           -0.091936 -0.095662 -0.092009 -0.091938  0.126348   \n",
            "여가 시간-독서                 0.050193  0.046885  0.050240  0.050190 -0.015298   \n",
            "한달 평균 독서 권 수             0.053175  0.051978  0.053207  0.053177  0.043716   \n",
            "독서 분야                    0.008093  0.008695  0.008074  0.008104  0.002117   \n",
            "독서-책 읽기 좋아함              0.002909 -0.000486  0.002971  0.002904  0.091229   \n",
            "독서-책 선물 좋아함              0.005297  0.005169  0.005353  0.005291  0.172034   \n",
            "동아리 활동 개수                0.021945  0.020240  0.021955  0.021953  0.134398   \n",
            "\n",
            "                             학교유형  고등학교 소재지  재학 중인 고등학교 유형   고등학교 계열  \\\n",
            "진로에 관한 생각과 태도-편견 및 고정관념 -0.009445 -0.065895      -0.009445  0.062912   \n",
            "혼자 공부하는 시간-주말           -0.254871 -0.070501      -0.254871  0.343369   \n",
            "여가 시간-독서                 0.017635  0.051765       0.017635  0.000734   \n",
            "한달 평균 독서 권 수            -0.011060  0.055080      -0.011060  0.041775   \n",
            "독서 분야                   -0.072671  0.013533      -0.072671  0.111251   \n",
            "독서-책 읽기 좋아함             -0.002228  0.001523      -0.002228  0.030429   \n",
            "독서-책 선물 좋아함             -0.028744  0.005882      -0.028744  0.037465   \n",
            "동아리 활동 개수               -0.160417  0.034982      -0.160417  0.211847   \n",
            "\n",
            "                         고등학교 계열 선택 이유  ...  (담임평가)교외 수상-학업  (담임평가)교외 수상-예체능  \\\n",
            "진로에 관한 생각과 태도-편견 및 고정관념       0.044319  ...        0.093232        -0.020867   \n",
            "혼자 공부하는 시간-주말                 0.261386  ...        0.113757        -0.056390   \n",
            "여가 시간-독서                      0.008200  ...        0.047435        -0.015482   \n",
            "한달 평균 독서 권 수                  0.043924  ...        0.046412        -0.017670   \n",
            "독서 분야                         0.084170  ...        0.026739        -0.017331   \n",
            "독서-책 읽기 좋아함                   0.037096  ...        0.066890        -0.014497   \n",
            "독서-책 선물 좋아함                   0.056106  ...        0.063985        -0.009504   \n",
            "동아리 활동 개수                     0.186828  ...        0.148107        -0.072387   \n",
            "\n",
            "                         (담임평가)교외 수상-기능/기술  (담임평가)교외 수상-품행  (담임평가)교외 수상-기타  \\\n",
            "진로에 관한 생각과 태도-편견 및 고정관념           0.032292        0.030366        0.026534   \n",
            "혼자 공부하는 시간-주말                     0.013717        0.029833        0.025491   \n",
            "여가 시간-독서                          0.027125        0.026558        0.015195   \n",
            "한달 평균 독서 권 수                      0.025307        0.012208        0.014714   \n",
            "독서 분야                             0.018449        0.025025        0.015917   \n",
            "독서-책 읽기 좋아함                       0.027974        0.020378        0.018401   \n",
            "독서-책 선물 좋아함                       0.037127        0.026099        0.007877   \n",
            "동아리 활동 개수                         0.035878        0.045147        0.037309   \n",
            "\n",
            "                         (담임평가)2학년 1학기 성적(등급)  (담임평가)학업관련 학부모 상담 경험  \\\n",
            "진로에 관한 생각과 태도-편견 및 고정관념             -0.169147             -0.061478   \n",
            "혼자 공부하는 시간-주말                       -0.234277             -0.097145   \n",
            "여가 시간-독서                            -0.091623             -0.052056   \n",
            "한달 평균 독서 권 수                        -0.077708             -0.042676   \n",
            "독서 분야                               -0.084849             -0.042971   \n",
            "독서-책 읽기 좋아함                         -0.114367             -0.036426   \n",
            "독서-책 선물 좋아함                         -0.130607             -0.024655   \n",
            "동아리 활동 개수                           -0.202332             -0.093046   \n",
            "\n",
            "                         (담임평가)생활 태도관련 학부모 상담 경험  (담임평가)진로 취업관련 학부모 상담 경험  \\\n",
            "진로에 관한 생각과 태도-편견 및 고정관념                -0.013638                -0.049790   \n",
            "혼자 공부하는 시간-주말                          -0.002761                -0.025156   \n",
            "여가 시간-독서                               -0.021953                -0.045790   \n",
            "한달 평균 독서 권 수                           -0.016142                -0.038067   \n",
            "독서 분야                                   0.000007                -0.019111   \n",
            "독서-책 읽기 좋아함                            -0.006688                -0.024400   \n",
            "독서-책 선물 좋아함                             0.014303                -0.019623   \n",
            "동아리 활동 개수                              -0.016202                -0.041267   \n",
            "\n",
            "                         학생 전체 가중치  \n",
            "진로에 관한 생각과 태도-편견 및 고정관념   0.023078  \n",
            "혼자 공부하는 시간-주말             0.244382  \n",
            "여가 시간-독서                 -0.038271  \n",
            "한달 평균 독서 권 수             -0.016684  \n",
            "독서 분야                     0.049407  \n",
            "독서-책 읽기 좋아함              -0.009259  \n",
            "독서-책 선물 좋아함               0.002627  \n",
            "동아리 활동 개수                 0.106342  \n",
            "\n",
            "[8 rows x 462 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler #정규화해주는 패키지\n",
        "from sklearn.model_selection import train_test_split #train set과 test set으로 나누어주는 패키지: 데이터 중에서 일부는 테스트용 데이터로 남겨두어서 너무 과도하게 학습하지 않도록 조절\n",
        "from sklearn.ensemble import RandomForestRegressor #RandomForestRegressor: https://zephyrus1111.tistory.com/253 를 참고해주세요.. 의사결정나무부터 알아야할 개념이 있지만, 결론적으로 변수 중요도를 뽑아서 볼 수 있다 !\n",
        "\n",
        "\n",
        "df1=df.drop(['독서 분야','독서 여부','여가 시간-독서','독서-책 읽기 좋아함','학생 전체 가중치','독서-필요한 경우에만 함','독서-책 선물 좋아함'],axis=1)\n",
        "df1=df1.replace(np.NaN, 0) #결측치들을 0으로 대치_임시방편\n",
        "\n",
        "X_data = df1[df1.drop(['한달 평균 독서 권 수'],axis=1).columns]\n",
        "y_data = df1[['한달 평균 독서 권 수']]\n",
        "\n",
        "ss = StandardScaler()\n",
        "X_scaled = ss.fit_transform(X_data)\n",
        "y_scaled = ss.fit_transform(y_data)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.1,shuffle=True)\n",
        "\n",
        "forest = RandomForestRegressor(n_estimators=500)\n",
        "forest.fit(x_train, y_train) #데이터 훈련\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "r9SgONXDEn9k",
        "outputId": "7ce999bb-a3fc-4617-9b1d-5bea8a49bf6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(n_estimators=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=500)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt # 득점모델 변수 중요도\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "ftr_importances_values = forest.feature_importances_ #변수 중요도 뽑기\n",
        "ftr_importances = pd.Series(ftr_importances_values, index=X_data.columns) #series 화\n",
        "ftr_top = ftr_importances.sort_values(ascending=False)[:30] #30개 내림차순 뽑기\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "sns.barplot(x=ftr_top, y=ftr_top.index) #barplot 생성\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sa-gkxf5HR80",
        "outputId": "ebddb872-a6a8-4d84-e403-860613fb2f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#t검정"
      ],
      "metadata": {
        "id": "0DG8v6lmWh_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jinro=[];efficacy=[];diversity=[]\n",
        "for name in df.columns:\n",
        "  if '진로에 관한' in name:\n",
        "    jinro.append(name)\n",
        "  elif '자신에 대한' in name:\n",
        "    efficacy.append(name)\n",
        "  elif '문화적' in name:\n",
        "    diversity.append(name)\n",
        "\n",
        "print(jinro, efficacy, diversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V87lwupwW7gX",
        "outputId": "fc69e15a-91ea-4757-889d-283353cfe566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['진로에 관한 생각과 태도-사례', '진로에 관한 생각과 태도-변화', '진로에 관한 생각과 태도-직업 윤리', '진로에 관한 생각과 태도-편견 및 고정관념', '진로에 관한 생각과 태도-고등교육 기관 종류', '진로에 관한 생각과 태도-대학 및 학과 정보 탐색', '진로에 관한 생각과 태도-직업 정보 탐색', '진로에 관한 생각과 태도-정보 판단', '진로에 관한 생각과 태도-학력 및 자격 정보', '진로에 관한 생각과 태도-진로 계획', '진로에 관한 생각과 태도-졸업 이후 진로 계획 여부', '진로에 관한 생각과 태도-진로 준비 방법', '진로에 관한 생각과 태도-진로 선택 기준', '진로에 관한 생각과 태도-어려움 극복 가능성'] ['자신에 대한 질문-잘하는 일', '자신에 대한 질문-좋아하는 일', '자신에 대한 질문-삶에서 중요한 일', '자신에 대한 질문-일에 대한 결정', '자신에 대한 질문-계획 수행', '자신에 대한 질문-자존감'] ['문화적 배경-이웃', '문화적 배경-친구', '문화적 배경-단짝', '문화적 배경-이성 친구', '문화적 배경-결혼']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['진로성숙도']=df[jinro].mean(axis=1)\n",
        "df['다문화수용성']=df[diversity].mean(axis=1)\n",
        "df['자기효능감']=df[efficacy].mean(axis=1)\n",
        "df=df.drop(jinro,axis=1)\n",
        "df=df.drop(efficacy,axis=1)\n",
        "df=df.drop(diversity,axis=1)"
      ],
      "metadata": {
        "id": "FDoF81npdJnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['한달평균독서권수']=df['한달 평균 독서 권 수']"
      ],
      "metadata": {
        "id": "P8bz5YZ3gWo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['한달평균독서권수'].corr(df['진로성숙도'],method='spearman'))\n",
        "print(df['한달평균독서권수'].corr(df['다문화수용성'],method='spearman'))\n",
        "print(df['한달평균독서권수'].corr(df['자기효능감'],method='spearman'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLhTt0Vegn7L",
        "outputId": "518428a1-5945-46df-89f0-9500ab46ad1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.22741727021564176\n",
            "0.15387808629447616\n",
            "0.13405861484267304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.formula.api import ols"
      ],
      "metadata": {
        "id": "M5LNakTDWkq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res1 = ols('한달평균독서권수 ~ 진로성숙도', data=df).fit()"
      ],
      "metadata": {
        "id": "GnsHFvjiWrsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "50nxXwDsgeH1",
        "outputId": "d805675a-c205-437e-ba2b-e8b61191451c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:               한달평균독서권수   R-squared:                       0.036\n",
              "Model:                            OLS   Adj. R-squared:                  0.036\n",
              "Method:                 Least Squares   F-statistic:                     396.2\n",
              "Date:                Sat, 24 Jun 2023   Prob (F-statistic):           1.45e-86\n",
              "Time:                        17:47:19   Log-Likelihood:                -28912.\n",
              "No. Observations:               10558   AIC:                         5.783e+04\n",
              "Df Residuals:                   10556   BIC:                         5.784e+04\n",
              "Df Model:                           1                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     -3.0228      0.210    -14.397      0.000      -3.434      -2.611\n",
              "진로성숙도          1.1697      0.059     19.904      0.000       1.054       1.285\n",
              "==============================================================================\n",
              "Omnibus:                     8350.479   Durbin-Watson:                   1.837\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           583030.615\n",
              "Skew:                           3.270   Prob(JB):                         0.00\n",
              "Kurtosis:                      38.813   Cond. No.                         22.2\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>한달평균독서권수</td>     <th>  R-squared:         </th> <td>   0.036</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.036</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   396.2</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 24 Jun 2023</td> <th>  Prob (F-statistic):</th> <td>1.45e-86</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:47:19</td>     <th>  Log-Likelihood:    </th> <td> -28912.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 10558</td>      <th>  AIC:               </th> <td>5.783e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 10556</td>      <th>  BIC:               </th> <td>5.784e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   -3.0228</td> <td>    0.210</td> <td>  -14.397</td> <td> 0.000</td> <td>   -3.434</td> <td>   -2.611</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>진로성숙도</th>     <td>    1.1697</td> <td>    0.059</td> <td>   19.904</td> <td> 0.000</td> <td>    1.054</td> <td>    1.285</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>8350.479</td> <th>  Durbin-Watson:     </th>  <td>   1.837</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>583030.615</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 3.270</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td>38.813</td>  <th>  Cond. No.          </th>  <td>    22.2</td> \n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res2 = ols('한달평균독서권수 ~ 자기효능감', data=df).fit()"
      ],
      "metadata": {
        "id": "YVvzslOShIEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "C2apPAbLhJcE",
        "outputId": "a1316e6a-2a85-404f-e923-fed6e1e89d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:               한달평균독서권수   R-squared:                       0.011\n",
              "Model:                            OLS   Adj. R-squared:                  0.011\n",
              "Method:                 Least Squares   F-statistic:                     116.0\n",
              "Date:                Sat, 24 Jun 2023   Prob (F-statistic):           6.69e-27\n",
              "Time:                        17:47:43   Log-Likelihood:                -29049.\n",
              "No. Observations:               10558   AIC:                         5.810e+04\n",
              "Df Residuals:                   10556   BIC:                         5.812e+04\n",
              "Df Model:                           1                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     -1.0650      0.204     -5.227      0.000      -1.464      -0.666\n",
              "자기효능감          0.5855      0.054     10.768      0.000       0.479       0.692\n",
              "==============================================================================\n",
              "Omnibus:                     8054.194   Durbin-Watson:                   1.815\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           530050.900\n",
              "Skew:                           3.103   Prob(JB):                         0.00\n",
              "Kurtosis:                      37.152   Cond. No.                         22.1\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>한달평균독서권수</td>     <th>  R-squared:         </th> <td>   0.011</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.011</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   116.0</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 24 Jun 2023</td> <th>  Prob (F-statistic):</th> <td>6.69e-27</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:47:43</td>     <th>  Log-Likelihood:    </th> <td> -29049.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 10558</td>      <th>  AIC:               </th> <td>5.810e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 10556</td>      <th>  BIC:               </th> <td>5.812e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   -1.0650</td> <td>    0.204</td> <td>   -5.227</td> <td> 0.000</td> <td>   -1.464</td> <td>   -0.666</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>자기효능감</th>     <td>    0.5855</td> <td>    0.054</td> <td>   10.768</td> <td> 0.000</td> <td>    0.479</td> <td>    0.692</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>8054.194</td> <th>  Durbin-Watson:     </th>  <td>   1.815</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>530050.900</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 3.103</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td>37.152</td>  <th>  Cond. No.          </th>  <td>    22.1</td> \n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res3 = ols('한달평균독서권수 ~ 다문화수용성', data=df).fit()"
      ],
      "metadata": {
        "id": "0GiTLZl6iJYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "FRCHvT9NiNTY",
        "outputId": "a2b3f5ff-8b31-48fe-f932-093d82ea0dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:               한달평균독서권수   R-squared:                       0.017\n",
              "Model:                            OLS   Adj. R-squared:                  0.017\n",
              "Method:                 Least Squares   F-statistic:                     180.4\n",
              "Date:                Sat, 24 Jun 2023   Prob (F-statistic):           8.43e-41\n",
              "Time:                        17:52:14   Log-Likelihood:                -29017.\n",
              "No. Observations:               10558   AIC:                         5.804e+04\n",
              "Df Residuals:                   10556   BIC:                         5.805e+04\n",
              "Df Model:                           1                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     -1.4369      0.192     -7.489      0.000      -1.813      -1.061\n",
              "다문화수용성         0.6630      0.049     13.433      0.000       0.566       0.760\n",
              "==============================================================================\n",
              "Omnibus:                     8105.596   Durbin-Watson:                   1.814\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           535448.150\n",
              "Skew:                           3.134   Prob(JB):                         0.00\n",
              "Kurtosis:                      37.320   Cond. No.                         21.6\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>한달평균독서권수</td>     <th>  R-squared:         </th> <td>   0.017</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.017</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   180.4</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 24 Jun 2023</td> <th>  Prob (F-statistic):</th> <td>8.43e-41</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:52:14</td>     <th>  Log-Likelihood:    </th> <td> -29017.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 10558</td>      <th>  AIC:               </th> <td>5.804e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 10556</td>      <th>  BIC:               </th> <td>5.805e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   -1.4369</td> <td>    0.192</td> <td>   -7.489</td> <td> 0.000</td> <td>   -1.813</td> <td>   -1.061</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>다문화수용성</th>    <td>    0.6630</td> <td>    0.049</td> <td>   13.433</td> <td> 0.000</td> <td>    0.566</td> <td>    0.760</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>8105.596</td> <th>  Durbin-Watson:     </th>  <td>   1.814</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>535448.150</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 3.134</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td>37.320</td>  <th>  Cond. No.          </th>  <td>    21.6</td> \n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_df=scaler.fit_transform(df.drop(['한달 평균 독서 권 수','한달평균독서권수'],axis=1))"
      ],
      "metadata": {
        "id": "XUPapyAAl_zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "df=df.replace(np.NaN,0)\n",
        "\n",
        "res=sm.OLS(df['한달평균독서권수'].values, sm.add_constant(scaled_df)).fit()"
      ],
      "metadata": {
        "id": "oHR0aVTMiyHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=res.summary()\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bZ6iv-LHjvWK",
        "outputId": "2f55e40d-e51d-48e1-ce63-ca79c7d0827f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.583\n",
              "Model:                            OLS   Adj. R-squared:                  0.565\n",
              "Method:                 Least Squares   F-statistic:                     32.36\n",
              "Date:                Sat, 24 Jun 2023   Prob (F-statistic):               0.00\n",
              "Time:                        18:10:21   Log-Likelihood:                -24491.\n",
              "No. Observations:               10558   AIC:                         4.986e+04\n",
              "Df Residuals:                   10120   BIC:                         5.304e+04\n",
              "Df Model:                         437                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          1.0927      0.024     44.660      0.000       1.045       1.141\n",
              "x1          6.855e+05    8.2e+05      0.836      0.403   -9.21e+05    2.29e+06\n",
              "x2             0.1681      0.129      1.299      0.194      -0.086       0.422\n",
              "x3         -1590.2324   1.12e+04     -0.142      0.887   -2.35e+04    2.03e+04\n",
              "x4          -6.84e+05   8.19e+05     -0.835      0.404   -2.29e+06    9.21e+05\n",
              "x5            -0.0065      0.027     -0.237      0.813      -0.060       0.047\n",
              "x6             0.0042      0.033      0.129      0.897      -0.060       0.068\n",
              "x7             0.2541      0.175      1.452      0.147      -0.089       0.597\n",
              "x8             0.0139      0.033      0.425      0.671      -0.050       0.078\n",
              "x9             0.1502      0.109      1.377      0.169      -0.064       0.364\n",
              "x10            0.0895      0.063      1.416      0.157      -0.034       0.213\n",
              "x11            0.2002      0.061      3.284      0.001       0.081       0.320\n",
              "x12            0.0910      0.076      1.195      0.232      -0.058       0.240\n",
              "x13           -0.0095      0.030     -0.314      0.754      -0.069       0.050\n",
              "x14            0.0222      0.026      0.837      0.403      -0.030       0.074\n",
              "x15            0.0140      0.026      0.539      0.590      -0.037       0.065\n",
              "x16            0.0131      0.026      0.508      0.612      -0.037       0.064\n",
              "x17            0.0110      0.032      0.339      0.735      -0.052       0.074\n",
              "x18            0.0222      0.036      0.621      0.535      -0.048       0.092\n",
              "x19            0.0014      0.033      0.042      0.967      -0.063       0.066\n",
              "x20           -0.0184      0.034     -0.542      0.588      -0.085       0.048\n",
              "x21            0.0850      0.030      2.815      0.005       0.026       0.144\n",
              "x22           -0.0447      0.035     -1.283      0.200      -0.113       0.024\n",
              "x23            0.0157      0.034      0.456      0.648      -0.052       0.083\n",
              "x24            0.0409      0.046      0.898      0.369      -0.048       0.130\n",
              "x25           -0.0983      0.046     -2.156      0.031      -0.188      -0.009\n",
              "x26            0.0873      0.043      2.021      0.043       0.003       0.172\n",
              "x27           -0.0374      0.038     -0.995      0.320      -0.111       0.036\n",
              "x28            0.0365      0.037      0.974      0.330      -0.037       0.110\n",
              "x29            0.0369      0.039      0.948      0.343      -0.039       0.113\n",
              "x30           -0.0576      0.044     -1.314      0.189      -0.143       0.028\n",
              "x31            0.0145      0.040      0.366      0.715      -0.063       0.092\n",
              "x32           -0.0360      0.031     -1.166      0.244      -0.097       0.025\n",
              "x33            0.0364      0.031      1.162      0.245      -0.025       0.098\n",
              "x34           -0.0398      0.033     -1.210      0.226      -0.104       0.025\n",
              "x35            0.0002      0.031      0.005      0.996      -0.061       0.062\n",
              "x36           -0.0433      0.037     -1.179      0.238      -0.115       0.029\n",
              "x37            0.0057      0.040      0.144      0.886      -0.072       0.084\n",
              "x38           -0.0310      0.037     -0.839      0.401      -0.103       0.041\n",
              "x39           -0.0294      0.041     -0.724      0.469      -0.109       0.050\n",
              "x40            0.0654      0.045      1.455      0.146      -0.023       0.153\n",
              "x41            0.0311      0.042      0.741      0.459      -0.051       0.113\n",
              "x42            0.0402      0.040      1.001      0.317      -0.038       0.119\n",
              "x43           -0.0655      0.045     -1.459      0.145      -0.153       0.022\n",
              "x44            0.0395      0.042      0.933      0.351      -0.043       0.122\n",
              "x45           -0.0278      0.038     -0.737      0.461      -0.102       0.046\n",
              "x46           -0.0251      0.033     -0.759      0.448      -0.090       0.040\n",
              "x47            0.0433      0.034      1.288      0.198      -0.023       0.109\n",
              "x48           -0.0027      0.037     -0.072      0.943      -0.076       0.071\n",
              "x49            0.0503      0.034      1.491      0.136      -0.016       0.116\n",
              "x50           -0.0474      0.032     -1.496      0.135      -0.110       0.015\n",
              "x51            0.0566      0.030      1.901      0.057      -0.002       0.115\n",
              "x52            0.1039      0.033      3.188      0.001       0.040       0.168\n",
              "x53            0.0202      0.030      0.673      0.501      -0.039       0.079\n",
              "x54            0.0231      0.043      0.542      0.588      -0.061       0.107\n",
              "x55            0.0209      0.036      0.588      0.557      -0.049       0.091\n",
              "x56           -0.0037      0.045     -0.084      0.933      -0.091       0.084\n",
              "x57           -0.0730      0.054     -1.356      0.175      -0.179       0.032\n",
              "x58           -0.0217      0.044     -0.496      0.620      -0.108       0.064\n",
              "x59            0.0417      0.057      0.728      0.467      -0.071       0.154\n",
              "x60            0.0646      0.050      1.284      0.199      -0.034       0.163\n",
              "x61           -0.0280      0.040     -0.696      0.486      -0.107       0.051\n",
              "x62           -0.0761      0.052     -1.456      0.146      -0.179       0.026\n",
              "x63            0.0206      0.064      0.324      0.746      -0.104       0.145\n",
              "x64            0.0867      0.049      1.778      0.075      -0.009       0.182\n",
              "x65           -0.0240      0.067     -0.358      0.720      -0.155       0.107\n",
              "x66            0.0892      0.073      1.216      0.224      -0.055       0.233\n",
              "x67            0.0523      0.053      0.986      0.324      -0.052       0.156\n",
              "x68           -0.1304      0.077     -1.693      0.091      -0.281       0.021\n",
              "x69           -0.1976      0.082     -2.402      0.016      -0.359      -0.036\n",
              "x70           -0.0494      0.055     -0.906      0.365      -0.156       0.058\n",
              "x71            0.2787      0.084      3.327      0.001       0.114       0.443\n",
              "x72            0.1229      0.085      1.451      0.147      -0.043       0.289\n",
              "x73            0.0504      0.057      0.880      0.379      -0.062       0.163\n",
              "x74           -0.2202      0.089     -2.469      0.014      -0.395      -0.045\n",
              "x75            0.0215      0.055      0.388      0.698      -0.087       0.130\n",
              "x76            0.0103      0.042      0.246      0.805      -0.071       0.092\n",
              "x77           -0.0402      0.060     -0.673      0.501      -0.157       0.077\n",
              "x78            0.0055      0.340      0.016      0.987      -0.661       0.672\n",
              "x79           -0.3313      0.247     -1.343      0.179      -0.815       0.152\n",
              "x80           -0.2623      0.346     -0.757      0.449      -0.941       0.417\n",
              "x81            0.0455      0.348      0.131      0.896      -0.636       0.727\n",
              "x82            0.2877      0.317      0.906      0.365      -0.335       0.910\n",
              "x83            0.0757      0.297      0.255      0.799      -0.507       0.658\n",
              "x84           -0.0283      0.246     -0.115      0.908      -0.510       0.453\n",
              "x85            0.2788      0.206      1.353      0.176      -0.125       0.683\n",
              "x86           -0.0037      0.180     -0.021      0.984      -0.357       0.350\n",
              "x87           -0.6424      0.320     -2.008      0.045      -1.270      -0.015\n",
              "x88            0.0244      0.338      0.072      0.942      -0.638       0.687\n",
              "x89           -0.1485      0.298     -0.498      0.618      -0.733       0.436\n",
              "x90            0.9528      1.169      0.815      0.415      -1.339       3.245\n",
              "x91            0.0885      0.147      0.603      0.546      -0.199       0.376\n",
              "x92           -0.4988      0.709     -0.704      0.482      -1.888       0.890\n",
              "x93            0.0058      0.060      0.097      0.923      -0.112       0.123\n",
              "x94            0.0144      0.032      0.456      0.648      -0.048       0.076\n",
              "x95            0.1408      0.087      1.616      0.106      -0.030       0.312\n",
              "x96            0.1507      0.088      1.719      0.086      -0.021       0.322\n",
              "x97           -0.0093      0.085     -0.109      0.913      -0.176       0.158\n",
              "x98            0.0378      0.086      0.439      0.661      -0.131       0.207\n",
              "x99            0.1073      0.109      0.983      0.326      -0.107       0.321\n",
              "x100           0.1145      0.109      1.052      0.293      -0.099       0.328\n",
              "x101          -0.1893      0.126     -1.501      0.133      -0.437       0.058\n",
              "x102          -0.2211      0.126     -1.752      0.080      -0.469       0.026\n",
              "x103          -0.0103      0.092     -0.112      0.910      -0.190       0.169\n",
              "x104          -0.0222      0.089     -0.250      0.803      -0.197       0.152\n",
              "x105           0.1147      0.126      0.911      0.362      -0.132       0.361\n",
              "x106           0.0748      0.124      0.605      0.545      -0.168       0.317\n",
              "x107           0.2229      0.145      1.538      0.124      -0.061       0.507\n",
              "x108           0.1872      0.143      1.307      0.191      -0.094       0.468\n",
              "x109          -0.3388      0.147     -2.305      0.021      -0.627      -0.051\n",
              "x110          -0.2798      0.144     -1.947      0.052      -0.561       0.002\n",
              "x111           0.2237      0.193      1.159      0.246      -0.155       0.602\n",
              "x112           0.2097      0.184      1.139      0.255      -0.151       0.571\n",
              "x113          -0.1959      0.156     -1.253      0.210      -0.502       0.110\n",
              "x114          -0.1904      0.145     -1.312      0.190      -0.475       0.094\n",
              "x115          -0.0435      0.113     -0.386      0.700      -0.264       0.177\n",
              "x116          -0.0202      0.110     -0.184      0.854      -0.235       0.195\n",
              "x117          -2.0340      2.422     -0.840      0.401      -6.782       2.714\n",
              "x118          -0.2062      0.298     -0.691      0.490      -0.791       0.379\n",
              "x119          -1.5753      1.578     -0.998      0.318      -4.669       1.519\n",
              "x120          -0.2848      0.206     -1.380      0.168      -0.689       0.120\n",
              "x121           0.7614      2.267      0.336      0.737      -3.683       5.205\n",
              "x122           0.1020      0.299      0.341      0.733      -0.485       0.689\n",
              "x123           4.6824      2.414      1.940      0.052      -0.050       9.415\n",
              "x124           0.5774      0.285      2.027      0.043       0.019       1.136\n",
              "x125          -2.2436      2.747     -0.817      0.414      -7.627       3.140\n",
              "x126          -0.1512      0.247     -0.613      0.540      -0.635       0.332\n",
              "x127          -2.5209      2.188     -1.152      0.249      -6.810       1.768\n",
              "x128          -0.3272      0.260     -1.257      0.209      -0.837       0.183\n",
              "x129           3.3387      2.791      1.196      0.232      -2.132       8.810\n",
              "x130           0.3136      0.230      1.366      0.172      -0.136       0.764\n",
              "x131          -0.0561      0.194     -0.290      0.772      -0.435       0.323\n",
              "x132          -0.0672      0.192     -0.350      0.727      -0.444       0.310\n",
              "x133          -0.0648      0.037     -1.741      0.082      -0.138       0.008\n",
              "x134           0.0548      0.032      1.691      0.091      -0.009       0.118\n",
              "x135           0.0590      0.033      1.814      0.070      -0.005       0.123\n",
              "x136           0.0256      0.031      0.816      0.415      -0.036       0.087\n",
              "x137           0.0411      0.036      1.131      0.258      -0.030       0.112\n",
              "x138          -0.0332      0.034     -0.962      0.336      -0.101       0.034\n",
              "x139          -0.0482      0.038     -1.284      0.199      -0.122       0.025\n",
              "x140           0.0583      0.034      1.718      0.086      -0.008       0.125\n",
              "x141          -0.0579      0.036     -1.619      0.106      -0.128       0.012\n",
              "x142           0.0419      0.036      1.148      0.251      -0.030       0.113\n",
              "x143          -0.0226      0.036     -0.631      0.528      -0.093       0.048\n",
              "x144          -0.0504      0.032     -1.570      0.117      -0.113       0.013\n",
              "x145           0.0415      0.036      1.143      0.253      -0.030       0.113\n",
              "x146          -0.0201      0.033     -0.601      0.548      -0.086       0.045\n",
              "x147           0.0659      0.034      1.966      0.049       0.000       0.132\n",
              "x148          -0.0563      0.033     -1.693      0.090      -0.122       0.009\n",
              "x149          -0.0655      0.033     -1.975      0.048      -0.131      -0.000\n",
              "x150          -0.0096      0.040     -0.242      0.809      -0.088       0.068\n",
              "x151           0.0223      0.036      0.619      0.536      -0.048       0.093\n",
              "x152           0.0169      0.033      0.505      0.614      -0.049       0.082\n",
              "x153          -0.0944      0.032     -2.990      0.003      -0.156      -0.032\n",
              "x154           0.0266      0.034      0.789      0.430      -0.040       0.093\n",
              "x155          -0.0028      0.036     -0.076      0.939      -0.074       0.068\n",
              "x156           0.0196      0.033      0.592      0.554      -0.045       0.084\n",
              "x157           0.0768      0.033      2.362      0.018       0.013       0.141\n",
              "x158          -0.0724      0.033     -2.219      0.026      -0.136      -0.008\n",
              "x159          -0.0224      0.032     -0.696      0.486      -0.085       0.041\n",
              "x160           0.0056      0.034      0.166      0.868      -0.061       0.072\n",
              "x161           0.0290      0.038      0.769      0.442      -0.045       0.103\n",
              "x162          -0.1396      0.284     -0.491      0.623      -0.697       0.418\n",
              "x163           0.3932      0.267      1.475      0.140      -0.129       0.916\n",
              "x164          -0.1866      0.408     -0.458      0.647      -0.985       0.612\n",
              "x165           0.1832      0.266      0.690      0.490      -0.338       0.704\n",
              "x166           0.0044      0.277      0.016      0.987      -0.539       0.548\n",
              "x167          -0.0195      0.246     -0.079      0.937      -0.503       0.463\n",
              "x168           0.1079      0.385      0.280      0.779      -0.646       0.862\n",
              "x169           0.2771      0.259      1.071      0.284      -0.230       0.785\n",
              "x170          -0.1742      0.274     -0.635      0.526      -0.712       0.364\n",
              "x171          -0.1424      0.253     -0.562      0.574      -0.639       0.354\n",
              "x172           0.4825      0.342      1.412      0.158      -0.187       1.152\n",
              "x173          -0.1215      0.268     -0.453      0.650      -0.647       0.404\n",
              "x174           0.1018      0.273      0.372      0.710      -0.434       0.638\n",
              "x175          -0.3053      0.460     -0.664      0.507      -1.207       0.596\n",
              "x176           0.2235      0.449      0.498      0.618      -0.656       1.103\n",
              "x177           0.1272      0.270      0.471      0.638      -0.402       0.656\n",
              "x178           0.0689      0.280      0.246      0.806      -0.480       0.618\n",
              "x179          -0.0077      0.330     -0.023      0.982      -0.655       0.640\n",
              "x180           0.5053      0.373      1.353      0.176      -0.227       1.237\n",
              "x181           0.1396      0.266      0.525      0.600      -0.382       0.661\n",
              "x182          -0.3147      0.265     -1.189      0.235      -0.833       0.204\n",
              "x183          -0.3819      0.489     -0.780      0.435      -1.341       0.577\n",
              "x184          -0.9383      0.835     -1.123      0.261      -2.576       0.699\n",
              "x185          -0.2065      0.396     -0.521      0.602      -0.983       0.570\n",
              "x186           0.0791      0.725      0.109      0.913      -1.341       1.500\n",
              "x187           0.0965      0.300      0.322      0.747      -0.491       0.684\n",
              "x188          -0.1669      0.288     -0.580      0.562      -0.731       0.397\n",
              "x189           0.0140      0.038      0.363      0.716      -0.061       0.089\n",
              "x190           0.0030      0.029      0.105      0.916      -0.053       0.059\n",
              "x191           0.1306      0.244      0.536      0.592      -0.347       0.608\n",
              "x192           0.1303      0.118      1.103      0.270      -0.101       0.362\n",
              "x193           0.0811      0.069      1.169      0.242      -0.055       0.217\n",
              "x194          -0.0194      0.143     -0.135      0.892      -0.301       0.262\n",
              "x195          -0.0819      0.259     -0.316      0.752      -0.590       0.426\n",
              "x196          -0.0507      0.077     -0.660      0.510      -0.201       0.100\n",
              "x197          -0.4266      0.178     -2.402      0.016      -0.775      -0.079\n",
              "x198           0.3961      0.173      2.296      0.022       0.058       0.734\n",
              "x199          -0.1117      0.075     -1.484      0.138      -0.259       0.036\n",
              "x200           0.0460      0.179      0.257      0.797      -0.305       0.397\n",
              "x201           0.0764      0.169      0.452      0.652      -0.255       0.408\n",
              "x202          -0.1859      0.066     -2.823      0.005      -0.315      -0.057\n",
              "x203           0.2124      0.075      2.818      0.005       0.065       0.360\n",
              "x204          -0.0025      0.071     -0.035      0.972      -0.141       0.136\n",
              "x205          -0.0076      0.038     -0.202      0.840      -0.081       0.066\n",
              "x206           0.6316      0.304      2.076      0.038       0.035       1.228\n",
              "x207          -0.0849      0.075     -1.128      0.259      -0.232       0.063\n",
              "x208           0.1313      0.145      0.904      0.366      -0.153       0.416\n",
              "x209          -0.6279      0.254     -2.475      0.013      -1.125      -0.131\n",
              "x210          -0.0219      0.086     -0.255      0.799      -0.190       0.146\n",
              "x211           0.3414      0.167      2.048      0.041       0.015       0.668\n",
              "x212          -0.3734      0.171     -2.178      0.029      -0.709      -0.037\n",
              "x213           0.0985      0.091      1.087      0.277      -0.079       0.276\n",
              "x214           0.0444      0.188      0.236      0.813      -0.324       0.413\n",
              "x215          -0.2225      0.172     -1.292      0.196      -0.560       0.115\n",
              "x216           0.2998      0.078      3.828      0.000       0.146       0.453\n",
              "x217          -0.2741      0.082     -3.328      0.001      -0.436      -0.113\n",
              "x218          -0.0369      0.035     -1.042      0.297      -0.106       0.033\n",
              "x219          -0.0323      0.035     -0.911      0.362      -0.102       0.037\n",
              "x220           0.0274      0.065      0.422      0.673      -0.100       0.155\n",
              "x221           0.0621      0.034      1.826      0.068      -0.005       0.129\n",
              "x222           0.0398      0.076      0.520      0.603      -0.110       0.190\n",
              "x223          -0.0584      0.075     -0.775      0.439      -0.206       0.089\n",
              "x224           0.0284      0.064      0.441      0.659      -0.098       0.155\n",
              "x225          -0.0917      0.070     -1.304      0.192      -0.230       0.046\n",
              "x226           0.0164      0.064      0.254      0.799      -0.110       0.143\n",
              "x227           0.0949      0.069      1.368      0.171      -0.041       0.231\n",
              "x228           0.0082      0.082      0.101      0.920      -0.152       0.168\n",
              "x229           0.0674      0.071      0.955      0.339      -0.071       0.206\n",
              "x230           0.0057      0.067      0.085      0.932      -0.125       0.137\n",
              "x231           0.1453      0.073      2.003      0.045       0.003       0.287\n",
              "x232           0.0736      0.076      0.972      0.331      -0.075       0.222\n",
              "x233          -0.0668      0.088     -0.757      0.449      -0.240       0.106\n",
              "x234          -0.1196      0.085     -1.412      0.158      -0.286       0.046\n",
              "x235          -0.0073      0.081     -0.090      0.928      -0.167       0.152\n",
              "x236          -0.0181      0.068     -0.266      0.791      -0.151       0.115\n",
              "x237          -0.0008      0.071     -0.011      0.991      -0.141       0.139\n",
              "x238          -0.1415      0.085     -1.658      0.097      -0.309       0.026\n",
              "x239           0.0516      0.080      0.643      0.520      -0.106       0.209\n",
              "x240          -0.0021      0.053     -0.040      0.968      -0.106       0.102\n",
              "x241          -0.0265      0.034     -0.781      0.435      -0.093       0.040\n",
              "x242           0.0128      0.068      0.188      0.851      -0.121       0.147\n",
              "x243          -0.0784      0.059     -1.328      0.184      -0.194       0.037\n",
              "x244          -0.0607      0.049     -1.242      0.214      -0.157       0.035\n",
              "x245          -0.0481      0.056     -0.862      0.389      -0.158       0.061\n",
              "x246          -0.0029      0.049     -0.058      0.954      -0.099       0.094\n",
              "x247          -0.0024      0.061     -0.040      0.968      -0.122       0.118\n",
              "x248           0.0184      0.070      0.264      0.792      -0.118       0.155\n",
              "x249          -0.0145      0.055     -0.261      0.794      -0.123       0.094\n",
              "x250           0.0032      0.053      0.061      0.951      -0.100       0.107\n",
              "x251          -0.0052      0.057     -0.091      0.927      -0.117       0.107\n",
              "x252          -0.0219      0.056     -0.391      0.696      -0.131       0.088\n",
              "x253           0.0349      0.068      0.514      0.607      -0.098       0.168\n",
              "x254           0.1182      0.071      1.675      0.094      -0.020       0.257\n",
              "x255           0.0280      0.061      0.462      0.644      -0.091       0.147\n",
              "x256          -0.1019      0.054     -1.875      0.061      -0.208       0.005\n",
              "x257           0.0787      0.056      1.408      0.159      -0.031       0.188\n",
              "x258           0.0361      0.059      0.612      0.541      -0.080       0.152\n",
              "x259          -0.0100      0.056     -0.176      0.860      -0.121       0.101\n",
              "x260          -0.0427      0.030     -1.432      0.152      -0.101       0.016\n",
              "x261           0.0077      0.031      0.245      0.806      -0.054       0.069\n",
              "x262           0.0223      0.030      0.736      0.462      -0.037       0.082\n",
              "x263           0.0334      0.031      1.080      0.280      -0.027       0.094\n",
              "x264          -0.0248      0.031     -0.806      0.420      -0.085       0.036\n",
              "x265           0.0287      0.033      0.868      0.385      -0.036       0.094\n",
              "x266           0.0159      0.048      0.330      0.742      -0.079       0.110\n",
              "x267           0.0559      0.050      1.127      0.260      -0.041       0.153\n",
              "x268          -0.0436      0.041     -1.054      0.292      -0.125       0.037\n",
              "x269           0.0061      0.034      0.179      0.858      -0.060       0.073\n",
              "x270           0.0194      0.026      0.761      0.446      -0.031       0.069\n",
              "x271           0.0926      0.030      3.082      0.002       0.034       0.151\n",
              "x272          -0.0033      0.030     -0.111      0.912      -0.063       0.056\n",
              "x273          -0.0290      0.028     -1.039      0.299      -0.084       0.026\n",
              "x274           0.0250      0.032      0.781      0.435      -0.038       0.088\n",
              "x275          -0.1156      0.028     -4.070      0.000      -0.171      -0.060\n",
              "x276          -0.0920      0.028     -3.273      0.001      -0.147      -0.037\n",
              "x277           0.8102      0.033     24.592      0.000       0.746       0.875\n",
              "x278          -0.0127      0.033     -0.380      0.704      -0.078       0.053\n",
              "x279          -0.0564      0.029     -1.931      0.054      -0.114       0.001\n",
              "x280          -0.0137      0.030     -0.454      0.650      -0.073       0.046\n",
              "x281          -0.0169      0.033     -0.518      0.604      -0.081       0.047\n",
              "x282           0.0280      0.029      0.974      0.330      -0.028       0.084\n",
              "x283          -0.0094      0.027     -0.353      0.724      -0.061       0.043\n",
              "x284          -0.0165      0.025     -0.649      0.516      -0.066       0.033\n",
              "x285           0.0020      0.026      0.076      0.939      -0.050       0.054\n",
              "x286          -0.0049      0.027     -0.185      0.853      -0.057       0.047\n",
              "x287           0.0104      0.027      0.387      0.699      -0.042       0.063\n",
              "x288           0.0192      0.028      0.673      0.501      -0.037       0.075\n",
              "x289          -0.0227      0.025     -0.893      0.372      -0.073       0.027\n",
              "x290           0.0558      0.026      2.172      0.030       0.005       0.106\n",
              "x291           0.0368      0.027      1.355      0.176      -0.016       0.090\n",
              "x292          -0.0151      0.039     -0.384      0.701      -0.092       0.062\n",
              "x293           0.0065      0.043      0.151      0.880      -0.078       0.091\n",
              "x294           0.0074      0.042      0.178      0.858      -0.074       0.089\n",
              "x295           0.0070      0.037      0.190      0.850      -0.066       0.080\n",
              "x296           0.0142      0.037      0.382      0.703      -0.059       0.087\n",
              "x297          -0.0258      0.036     -0.713      0.476      -0.097       0.045\n",
              "x298          -0.0197      0.037     -0.532      0.595      -0.092       0.053\n",
              "x299          -0.0010      0.040     -0.026      0.979      -0.080       0.078\n",
              "x300           0.0550      0.036      1.536      0.125      -0.015       0.125\n",
              "x301          -2.1638      0.044    -49.112      0.000      -2.250      -2.077\n",
              "x302           0.1656      0.040      4.136      0.000       0.087       0.244\n",
              "x303          -0.1838      0.030     -6.109      0.000      -0.243      -0.125\n",
              "x304           0.3516      0.039      9.124      0.000       0.276       0.427\n",
              "x305          -0.0741      0.035     -2.106      0.035      -0.143      -0.005\n",
              "x306           0.0313      0.029      1.073      0.283      -0.026       0.088\n",
              "x307          -0.0290      0.028     -1.026      0.305      -0.084       0.026\n",
              "x308           0.0016      0.028      0.060      0.952      -0.052       0.056\n",
              "x309           0.0019      0.105      0.018      0.986      -0.204       0.208\n",
              "x310          -0.0296      0.081     -0.366      0.714      -0.188       0.129\n",
              "x311           0.0688      0.046      1.512      0.131      -0.020       0.158\n",
              "x312          -0.0211      0.042     -0.508      0.611      -0.103       0.060\n",
              "x313           0.0186      0.030      0.621      0.534      -0.040       0.077\n",
              "x314           0.0560      0.071      0.794      0.427      -0.082       0.194\n",
              "x315          -0.0811      0.059     -1.381      0.167      -0.196       0.034\n",
              "x316           0.0281      0.032      0.876      0.381      -0.035       0.091\n",
              "x317          -0.0255      0.031     -0.817      0.414      -0.087       0.036\n",
              "x318          -0.0393      0.031     -1.286      0.199      -0.099       0.021\n",
              "x319          -0.0509      0.030     -1.679      0.093      -0.110       0.009\n",
              "x320           0.0223      0.060      0.374      0.708      -0.095       0.139\n",
              "x321          -0.0104      0.062     -0.167      0.868      -0.132       0.112\n",
              "x322          -0.0762      0.055     -1.392      0.164      -0.184       0.031\n",
              "x323           0.0348      0.060      0.585      0.558      -0.082       0.151\n",
              "x324           0.0186      0.033      0.559      0.576      -0.047       0.084\n",
              "x325          -0.0102      0.032     -0.317      0.751      -0.074       0.053\n",
              "x326          -0.0330      0.029     -1.138      0.255      -0.090       0.024\n",
              "x327          -0.0269      0.030     -0.897      0.370      -0.086       0.032\n",
              "x328           0.0246      0.030      0.810      0.418      -0.035       0.084\n",
              "x329          -0.0173      0.029     -0.603      0.546      -0.074       0.039\n",
              "x330          -0.0353      0.143     -0.246      0.806      -0.317       0.246\n",
              "x331           0.1126      0.055      2.044      0.041       0.005       0.220\n",
              "x332           0.2919      0.221      1.319      0.187      -0.142       0.726\n",
              "x333          -0.3300      0.230     -1.437      0.151      -0.780       0.120\n",
              "x334          -0.1802      0.203     -0.887      0.375      -0.579       0.218\n",
              "x335           0.1139      0.200      0.569      0.570      -0.279       0.507\n",
              "x336          -0.1177      0.138     -0.854      0.393      -0.388       0.153\n",
              "x337           0.0229      0.071      0.323      0.746      -0.116       0.162\n",
              "x338           0.0886      0.057      1.542      0.123      -0.024       0.201\n",
              "x339          -0.0352      0.049     -0.724      0.469      -0.130       0.060\n",
              "x340           0.1585      0.102      1.559      0.119      -0.041       0.358\n",
              "x341          -0.0573      0.089     -0.642      0.521      -0.232       0.118\n",
              "x342          -0.4494      0.157     -2.870      0.004      -0.756      -0.142\n",
              "x343          -0.0125      0.039     -0.320      0.749      -0.089       0.064\n",
              "x344           0.0511      0.033      1.548      0.122      -0.014       0.116\n",
              "x345           0.0045      0.028      0.162      0.871      -0.050       0.059\n",
              "x346           0.0777      0.035      2.231      0.026       0.009       0.146\n",
              "x347           0.0245      0.026      0.958      0.338      -0.026       0.075\n",
              "x348           0.0769      0.026      2.992      0.003       0.027       0.127\n",
              "x349           0.0231      0.071      0.327      0.744      -0.115       0.161\n",
              "x350           0.1325      0.112      1.185      0.236      -0.087       0.352\n",
              "x351          -0.0151      0.035     -0.432      0.666      -0.084       0.054\n",
              "x352           0.0229      0.075      0.305      0.760      -0.124       0.170\n",
              "x353           0.0831      0.066      1.265      0.206      -0.046       0.212\n",
              "x354           0.2255      0.190      1.184      0.236      -0.148       0.599\n",
              "x355          -0.2711      0.198     -1.372      0.170      -0.658       0.116\n",
              "x356          -0.0508      0.047     -1.070      0.285      -0.144       0.042\n",
              "x357           0.0045      0.074      0.061      0.952      -0.140       0.149\n",
              "x358          -0.0490      0.073     -0.671      0.502      -0.192       0.094\n",
              "x359           0.0365      0.267      0.137      0.891      -0.486       0.559\n",
              "x360          -0.1348      0.261     -0.517      0.605      -0.646       0.376\n",
              "x361           0.1159      0.285      0.407      0.684      -0.442       0.674\n",
              "x362           0.1350      0.101      1.332      0.183      -0.064       0.334\n",
              "x363          -0.0504      0.039     -1.302      0.193      -0.126       0.025\n",
              "x364          -0.0398      0.060     -0.660      0.509      -0.158       0.078\n",
              "x365          -0.0118      0.181     -0.066      0.948      -0.366       0.342\n",
              "x366           0.0981      0.114      0.859      0.391      -0.126       0.322\n",
              "x367           0.0406      0.045      0.904      0.366      -0.047       0.129\n",
              "x368          -0.1987      0.221     -0.897      0.370      -0.633       0.235\n",
              "x369           0.3236      0.163      1.989      0.047       0.005       0.643\n",
              "x370          -0.3139      0.165     -1.905      0.057      -0.637       0.009\n",
              "x371          -0.0762      0.039     -1.959      0.050      -0.152    4.56e-05\n",
              "x372           0.2329      0.188      1.241      0.215      -0.135       0.601\n",
              "x373           0.0091      0.036      0.255      0.799      -0.061       0.079\n",
              "x374           0.0311      0.232      0.134      0.893      -0.424       0.486\n",
              "x375           0.0423      0.240      0.176      0.860      -0.428       0.512\n",
              "x376           0.0058      0.167      0.035      0.972      -0.321       0.333\n",
              "x377          -0.1670      0.085     -1.954      0.051      -0.335       0.001\n",
              "x378           0.0226      0.027      0.840      0.401      -0.030       0.075\n",
              "x379          -0.0341      0.026     -1.312      0.190      -0.085       0.017\n",
              "x380          -0.0039      0.026     -0.148      0.882      -0.055       0.047\n",
              "x381          -0.0194      0.026     -0.756      0.449      -0.070       0.031\n",
              "x382          -0.0040      0.027     -0.152      0.880      -0.056       0.048\n",
              "x383           0.0204      0.026      0.787      0.431      -0.030       0.071\n",
              "x384          -0.0769      0.030     -2.585      0.010      -0.135      -0.019\n",
              "x385          -0.0047      0.030     -0.157      0.875      -0.063       0.053\n",
              "x386          -0.0283      0.027     -1.036      0.300      -0.082       0.025\n",
              "x387          -0.0106      0.027     -0.391      0.696      -0.064       0.042\n",
              "x388          -0.0312      0.036     -0.876      0.381      -0.101       0.039\n",
              "x389          -0.0218      0.032     -0.676      0.499      -0.085       0.041\n",
              "x390           0.0068      0.034      0.201      0.841      -0.060       0.074\n",
              "x391          -0.0419      0.033     -1.256      0.209      -0.107       0.023\n",
              "x392           0.0530      0.038      1.403      0.161      -0.021       0.127\n",
              "x393          -0.0361      0.034     -1.077      0.281      -0.102       0.030\n",
              "x394           0.0060      0.032      0.189      0.850      -0.056       0.068\n",
              "x395           0.0103      0.032      0.321      0.748      -0.052       0.073\n",
              "x396           0.0067      0.027      0.249      0.803      -0.046       0.060\n",
              "x397          -0.0088      0.032     -0.277      0.782      -0.071       0.053\n",
              "x398          -0.0041      0.033     -0.125      0.901      -0.068       0.060\n",
              "x399           0.0484      0.031      1.559      0.119      -0.012       0.109\n",
              "x400           0.0414      0.072      0.578      0.563      -0.099       0.182\n",
              "x401           0.0589      0.073      0.811      0.417      -0.083       0.201\n",
              "x402           0.0011      0.109      0.010      0.992      -0.213       0.216\n",
              "x403          -0.0540      0.112     -0.482      0.630      -0.274       0.166\n",
              "x404          -0.0241      0.036     -0.669      0.504      -0.095       0.046\n",
              "x405           0.0096      0.027      0.358      0.720      -0.043       0.062\n",
              "x406           0.0007      0.027      0.026      0.979      -0.052       0.054\n",
              "x407           0.0003      0.040      0.008      0.994      -0.078       0.078\n",
              "x408           0.0976      0.032      3.047      0.002       0.035       0.160\n",
              "x409           0.0281      0.025      1.105      0.269      -0.022       0.078\n",
              "x410           0.0114      0.028      0.408      0.683      -0.043       0.066\n",
              "x411          -0.0514      0.027     -1.905      0.057      -0.104       0.001\n",
              "x412           0.0032      0.026      0.124      0.901      -0.048       0.054\n",
              "x413          -0.1018      0.050     -2.018      0.044      -0.201      -0.003\n",
              "x414          -0.0057      0.033     -0.172      0.864      -0.071       0.060\n",
              "x415          -0.0041      0.038     -0.107      0.915      -0.079       0.071\n",
              "x416          -0.0260      0.033     -0.789      0.430      -0.091       0.039\n",
              "x417           0.0522      0.029      1.790      0.073      -0.005       0.109\n",
              "x418          -0.1136      0.033     -3.421      0.001      -0.179      -0.049\n",
              "x419           0.0029      0.035      0.082      0.935      -0.066       0.072\n",
              "x420           0.0005      0.048      0.011      0.991      -0.093       0.094\n",
              "x421           0.0959      0.040      2.416      0.016       0.018       0.174\n",
              "x422          -0.0003      0.029     -0.011      0.991      -0.056       0.056\n",
              "x423          -0.0106      0.027     -0.390      0.696      -0.064       0.043\n",
              "x424          -0.0213      0.033     -0.649      0.517      -0.086       0.043\n",
              "x425           0.0463      0.026      1.766      0.077      -0.005       0.098\n",
              "x426           0.0010      0.079      0.013      0.989      -0.153       0.156\n",
              "x427          -0.0220      0.043     -0.515      0.607      -0.106       0.062\n",
              "x428           0.0240      0.058      0.416      0.678      -0.089       0.137\n",
              "x429           0.0007      0.042      0.017      0.986      -0.082       0.084\n",
              "x430           0.0221      0.031      0.702      0.483      -0.040       0.084\n",
              "x431          -0.0282      0.028     -0.999      0.318      -0.084       0.027\n",
              "x432           0.0663      0.049      1.347      0.178      -0.030       0.163\n",
              "x433          -0.0866      0.040     -2.184      0.029      -0.164      -0.009\n",
              "x434          -0.0074      0.034     -0.217      0.828      -0.075       0.060\n",
              "x435           0.0759      0.039      1.947      0.052      -0.001       0.152\n",
              "x436          -0.0267      0.042     -0.629      0.530      -0.110       0.057\n",
              "x437           0.0022      0.040      0.055      0.956      -0.076       0.081\n",
              "x438          -0.0040      0.028     -0.143      0.886      -0.059       0.051\n",
              "x439           0.0527      0.037      1.441      0.150      -0.019       0.124\n",
              "==============================================================================\n",
              "Omnibus:                    14442.551   Durbin-Watson:                   1.896\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          5402600.586\n",
              "Skew:                           7.767   Prob(JB):                         0.00\n",
              "Kurtosis:                     112.725   Cond. No.                     1.39e+16\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The smallest eigenvalue is 3.04e-27. This might indicate that there are\n",
              "strong multicollinearity problems or that the design matrix is singular.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.583</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.565</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   32.36</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 24 Jun 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>18:10:21</td>     <th>  Log-Likelihood:    </th> <td> -24491.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 10558</td>      <th>  AIC:               </th> <td>4.986e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 10120</td>      <th>  BIC:               </th> <td>5.304e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>   437</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    1.0927</td> <td>    0.024</td> <td>   44.660</td> <td> 0.000</td> <td>    1.045</td> <td>    1.141</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td> 6.855e+05</td> <td>  8.2e+05</td> <td>    0.836</td> <td> 0.403</td> <td>-9.21e+05</td> <td> 2.29e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    0.1681</td> <td>    0.129</td> <td>    1.299</td> <td> 0.194</td> <td>   -0.086</td> <td>    0.422</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>-1590.2324</td> <td> 1.12e+04</td> <td>   -0.142</td> <td> 0.887</td> <td>-2.35e+04</td> <td> 2.03e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td> -6.84e+05</td> <td> 8.19e+05</td> <td>   -0.835</td> <td> 0.404</td> <td>-2.29e+06</td> <td> 9.21e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>   -0.0065</td> <td>    0.027</td> <td>   -0.237</td> <td> 0.813</td> <td>   -0.060</td> <td>    0.047</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>    0.0042</td> <td>    0.033</td> <td>    0.129</td> <td> 0.897</td> <td>   -0.060</td> <td>    0.068</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>    0.2541</td> <td>    0.175</td> <td>    1.452</td> <td> 0.147</td> <td>   -0.089</td> <td>    0.597</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>    0.0139</td> <td>    0.033</td> <td>    0.425</td> <td> 0.671</td> <td>   -0.050</td> <td>    0.078</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>    0.1502</td> <td>    0.109</td> <td>    1.377</td> <td> 0.169</td> <td>   -0.064</td> <td>    0.364</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>    0.0895</td> <td>    0.063</td> <td>    1.416</td> <td> 0.157</td> <td>   -0.034</td> <td>    0.213</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>    0.2002</td> <td>    0.061</td> <td>    3.284</td> <td> 0.001</td> <td>    0.081</td> <td>    0.320</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td>    0.0910</td> <td>    0.076</td> <td>    1.195</td> <td> 0.232</td> <td>   -0.058</td> <td>    0.240</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x13</th>   <td>   -0.0095</td> <td>    0.030</td> <td>   -0.314</td> <td> 0.754</td> <td>   -0.069</td> <td>    0.050</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x14</th>   <td>    0.0222</td> <td>    0.026</td> <td>    0.837</td> <td> 0.403</td> <td>   -0.030</td> <td>    0.074</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x15</th>   <td>    0.0140</td> <td>    0.026</td> <td>    0.539</td> <td> 0.590</td> <td>   -0.037</td> <td>    0.065</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x16</th>   <td>    0.0131</td> <td>    0.026</td> <td>    0.508</td> <td> 0.612</td> <td>   -0.037</td> <td>    0.064</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x17</th>   <td>    0.0110</td> <td>    0.032</td> <td>    0.339</td> <td> 0.735</td> <td>   -0.052</td> <td>    0.074</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x18</th>   <td>    0.0222</td> <td>    0.036</td> <td>    0.621</td> <td> 0.535</td> <td>   -0.048</td> <td>    0.092</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x19</th>   <td>    0.0014</td> <td>    0.033</td> <td>    0.042</td> <td> 0.967</td> <td>   -0.063</td> <td>    0.066</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x20</th>   <td>   -0.0184</td> <td>    0.034</td> <td>   -0.542</td> <td> 0.588</td> <td>   -0.085</td> <td>    0.048</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x21</th>   <td>    0.0850</td> <td>    0.030</td> <td>    2.815</td> <td> 0.005</td> <td>    0.026</td> <td>    0.144</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x22</th>   <td>   -0.0447</td> <td>    0.035</td> <td>   -1.283</td> <td> 0.200</td> <td>   -0.113</td> <td>    0.024</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x23</th>   <td>    0.0157</td> <td>    0.034</td> <td>    0.456</td> <td> 0.648</td> <td>   -0.052</td> <td>    0.083</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x24</th>   <td>    0.0409</td> <td>    0.046</td> <td>    0.898</td> <td> 0.369</td> <td>   -0.048</td> <td>    0.130</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x25</th>   <td>   -0.0983</td> <td>    0.046</td> <td>   -2.156</td> <td> 0.031</td> <td>   -0.188</td> <td>   -0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x26</th>   <td>    0.0873</td> <td>    0.043</td> <td>    2.021</td> <td> 0.043</td> <td>    0.003</td> <td>    0.172</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x27</th>   <td>   -0.0374</td> <td>    0.038</td> <td>   -0.995</td> <td> 0.320</td> <td>   -0.111</td> <td>    0.036</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x28</th>   <td>    0.0365</td> <td>    0.037</td> <td>    0.974</td> <td> 0.330</td> <td>   -0.037</td> <td>    0.110</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x29</th>   <td>    0.0369</td> <td>    0.039</td> <td>    0.948</td> <td> 0.343</td> <td>   -0.039</td> <td>    0.113</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x30</th>   <td>   -0.0576</td> <td>    0.044</td> <td>   -1.314</td> <td> 0.189</td> <td>   -0.143</td> <td>    0.028</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x31</th>   <td>    0.0145</td> <td>    0.040</td> <td>    0.366</td> <td> 0.715</td> <td>   -0.063</td> <td>    0.092</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x32</th>   <td>   -0.0360</td> <td>    0.031</td> <td>   -1.166</td> <td> 0.244</td> <td>   -0.097</td> <td>    0.025</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x33</th>   <td>    0.0364</td> <td>    0.031</td> <td>    1.162</td> <td> 0.245</td> <td>   -0.025</td> <td>    0.098</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x34</th>   <td>   -0.0398</td> <td>    0.033</td> <td>   -1.210</td> <td> 0.226</td> <td>   -0.104</td> <td>    0.025</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x35</th>   <td>    0.0002</td> <td>    0.031</td> <td>    0.005</td> <td> 0.996</td> <td>   -0.061</td> <td>    0.062</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x36</th>   <td>   -0.0433</td> <td>    0.037</td> <td>   -1.179</td> <td> 0.238</td> <td>   -0.115</td> <td>    0.029</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x37</th>   <td>    0.0057</td> <td>    0.040</td> <td>    0.144</td> <td> 0.886</td> <td>   -0.072</td> <td>    0.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x38</th>   <td>   -0.0310</td> <td>    0.037</td> <td>   -0.839</td> <td> 0.401</td> <td>   -0.103</td> <td>    0.041</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x39</th>   <td>   -0.0294</td> <td>    0.041</td> <td>   -0.724</td> <td> 0.469</td> <td>   -0.109</td> <td>    0.050</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x40</th>   <td>    0.0654</td> <td>    0.045</td> <td>    1.455</td> <td> 0.146</td> <td>   -0.023</td> <td>    0.153</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x41</th>   <td>    0.0311</td> <td>    0.042</td> <td>    0.741</td> <td> 0.459</td> <td>   -0.051</td> <td>    0.113</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x42</th>   <td>    0.0402</td> <td>    0.040</td> <td>    1.001</td> <td> 0.317</td> <td>   -0.038</td> <td>    0.119</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x43</th>   <td>   -0.0655</td> <td>    0.045</td> <td>   -1.459</td> <td> 0.145</td> <td>   -0.153</td> <td>    0.022</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x44</th>   <td>    0.0395</td> <td>    0.042</td> <td>    0.933</td> <td> 0.351</td> <td>   -0.043</td> <td>    0.122</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x45</th>   <td>   -0.0278</td> <td>    0.038</td> <td>   -0.737</td> <td> 0.461</td> <td>   -0.102</td> <td>    0.046</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x46</th>   <td>   -0.0251</td> <td>    0.033</td> <td>   -0.759</td> <td> 0.448</td> <td>   -0.090</td> <td>    0.040</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x47</th>   <td>    0.0433</td> <td>    0.034</td> <td>    1.288</td> <td> 0.198</td> <td>   -0.023</td> <td>    0.109</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x48</th>   <td>   -0.0027</td> <td>    0.037</td> <td>   -0.072</td> <td> 0.943</td> <td>   -0.076</td> <td>    0.071</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x49</th>   <td>    0.0503</td> <td>    0.034</td> <td>    1.491</td> <td> 0.136</td> <td>   -0.016</td> <td>    0.116</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x50</th>   <td>   -0.0474</td> <td>    0.032</td> <td>   -1.496</td> <td> 0.135</td> <td>   -0.110</td> <td>    0.015</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x51</th>   <td>    0.0566</td> <td>    0.030</td> <td>    1.901</td> <td> 0.057</td> <td>   -0.002</td> <td>    0.115</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x52</th>   <td>    0.1039</td> <td>    0.033</td> <td>    3.188</td> <td> 0.001</td> <td>    0.040</td> <td>    0.168</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x53</th>   <td>    0.0202</td> <td>    0.030</td> <td>    0.673</td> <td> 0.501</td> <td>   -0.039</td> <td>    0.079</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x54</th>   <td>    0.0231</td> <td>    0.043</td> <td>    0.542</td> <td> 0.588</td> <td>   -0.061</td> <td>    0.107</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x55</th>   <td>    0.0209</td> <td>    0.036</td> <td>    0.588</td> <td> 0.557</td> <td>   -0.049</td> <td>    0.091</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x56</th>   <td>   -0.0037</td> <td>    0.045</td> <td>   -0.084</td> <td> 0.933</td> <td>   -0.091</td> <td>    0.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x57</th>   <td>   -0.0730</td> <td>    0.054</td> <td>   -1.356</td> <td> 0.175</td> <td>   -0.179</td> <td>    0.032</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x58</th>   <td>   -0.0217</td> <td>    0.044</td> <td>   -0.496</td> <td> 0.620</td> <td>   -0.108</td> <td>    0.064</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x59</th>   <td>    0.0417</td> <td>    0.057</td> <td>    0.728</td> <td> 0.467</td> <td>   -0.071</td> <td>    0.154</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x60</th>   <td>    0.0646</td> <td>    0.050</td> <td>    1.284</td> <td> 0.199</td> <td>   -0.034</td> <td>    0.163</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x61</th>   <td>   -0.0280</td> <td>    0.040</td> <td>   -0.696</td> <td> 0.486</td> <td>   -0.107</td> <td>    0.051</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x62</th>   <td>   -0.0761</td> <td>    0.052</td> <td>   -1.456</td> <td> 0.146</td> <td>   -0.179</td> <td>    0.026</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x63</th>   <td>    0.0206</td> <td>    0.064</td> <td>    0.324</td> <td> 0.746</td> <td>   -0.104</td> <td>    0.145</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x64</th>   <td>    0.0867</td> <td>    0.049</td> <td>    1.778</td> <td> 0.075</td> <td>   -0.009</td> <td>    0.182</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x65</th>   <td>   -0.0240</td> <td>    0.067</td> <td>   -0.358</td> <td> 0.720</td> <td>   -0.155</td> <td>    0.107</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x66</th>   <td>    0.0892</td> <td>    0.073</td> <td>    1.216</td> <td> 0.224</td> <td>   -0.055</td> <td>    0.233</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x67</th>   <td>    0.0523</td> <td>    0.053</td> <td>    0.986</td> <td> 0.324</td> <td>   -0.052</td> <td>    0.156</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x68</th>   <td>   -0.1304</td> <td>    0.077</td> <td>   -1.693</td> <td> 0.091</td> <td>   -0.281</td> <td>    0.021</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x69</th>   <td>   -0.1976</td> <td>    0.082</td> <td>   -2.402</td> <td> 0.016</td> <td>   -0.359</td> <td>   -0.036</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x70</th>   <td>   -0.0494</td> <td>    0.055</td> <td>   -0.906</td> <td> 0.365</td> <td>   -0.156</td> <td>    0.058</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x71</th>   <td>    0.2787</td> <td>    0.084</td> <td>    3.327</td> <td> 0.001</td> <td>    0.114</td> <td>    0.443</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x72</th>   <td>    0.1229</td> <td>    0.085</td> <td>    1.451</td> <td> 0.147</td> <td>   -0.043</td> <td>    0.289</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x73</th>   <td>    0.0504</td> <td>    0.057</td> <td>    0.880</td> <td> 0.379</td> <td>   -0.062</td> <td>    0.163</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x74</th>   <td>   -0.2202</td> <td>    0.089</td> <td>   -2.469</td> <td> 0.014</td> <td>   -0.395</td> <td>   -0.045</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x75</th>   <td>    0.0215</td> <td>    0.055</td> <td>    0.388</td> <td> 0.698</td> <td>   -0.087</td> <td>    0.130</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x76</th>   <td>    0.0103</td> <td>    0.042</td> <td>    0.246</td> <td> 0.805</td> <td>   -0.071</td> <td>    0.092</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x77</th>   <td>   -0.0402</td> <td>    0.060</td> <td>   -0.673</td> <td> 0.501</td> <td>   -0.157</td> <td>    0.077</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x78</th>   <td>    0.0055</td> <td>    0.340</td> <td>    0.016</td> <td> 0.987</td> <td>   -0.661</td> <td>    0.672</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x79</th>   <td>   -0.3313</td> <td>    0.247</td> <td>   -1.343</td> <td> 0.179</td> <td>   -0.815</td> <td>    0.152</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x80</th>   <td>   -0.2623</td> <td>    0.346</td> <td>   -0.757</td> <td> 0.449</td> <td>   -0.941</td> <td>    0.417</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x81</th>   <td>    0.0455</td> <td>    0.348</td> <td>    0.131</td> <td> 0.896</td> <td>   -0.636</td> <td>    0.727</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x82</th>   <td>    0.2877</td> <td>    0.317</td> <td>    0.906</td> <td> 0.365</td> <td>   -0.335</td> <td>    0.910</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x83</th>   <td>    0.0757</td> <td>    0.297</td> <td>    0.255</td> <td> 0.799</td> <td>   -0.507</td> <td>    0.658</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x84</th>   <td>   -0.0283</td> <td>    0.246</td> <td>   -0.115</td> <td> 0.908</td> <td>   -0.510</td> <td>    0.453</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x85</th>   <td>    0.2788</td> <td>    0.206</td> <td>    1.353</td> <td> 0.176</td> <td>   -0.125</td> <td>    0.683</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x86</th>   <td>   -0.0037</td> <td>    0.180</td> <td>   -0.021</td> <td> 0.984</td> <td>   -0.357</td> <td>    0.350</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x87</th>   <td>   -0.6424</td> <td>    0.320</td> <td>   -2.008</td> <td> 0.045</td> <td>   -1.270</td> <td>   -0.015</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x88</th>   <td>    0.0244</td> <td>    0.338</td> <td>    0.072</td> <td> 0.942</td> <td>   -0.638</td> <td>    0.687</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x89</th>   <td>   -0.1485</td> <td>    0.298</td> <td>   -0.498</td> <td> 0.618</td> <td>   -0.733</td> <td>    0.436</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x90</th>   <td>    0.9528</td> <td>    1.169</td> <td>    0.815</td> <td> 0.415</td> <td>   -1.339</td> <td>    3.245</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x91</th>   <td>    0.0885</td> <td>    0.147</td> <td>    0.603</td> <td> 0.546</td> <td>   -0.199</td> <td>    0.376</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x92</th>   <td>   -0.4988</td> <td>    0.709</td> <td>   -0.704</td> <td> 0.482</td> <td>   -1.888</td> <td>    0.890</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x93</th>   <td>    0.0058</td> <td>    0.060</td> <td>    0.097</td> <td> 0.923</td> <td>   -0.112</td> <td>    0.123</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x94</th>   <td>    0.0144</td> <td>    0.032</td> <td>    0.456</td> <td> 0.648</td> <td>   -0.048</td> <td>    0.076</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x95</th>   <td>    0.1408</td> <td>    0.087</td> <td>    1.616</td> <td> 0.106</td> <td>   -0.030</td> <td>    0.312</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x96</th>   <td>    0.1507</td> <td>    0.088</td> <td>    1.719</td> <td> 0.086</td> <td>   -0.021</td> <td>    0.322</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x97</th>   <td>   -0.0093</td> <td>    0.085</td> <td>   -0.109</td> <td> 0.913</td> <td>   -0.176</td> <td>    0.158</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x98</th>   <td>    0.0378</td> <td>    0.086</td> <td>    0.439</td> <td> 0.661</td> <td>   -0.131</td> <td>    0.207</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x99</th>   <td>    0.1073</td> <td>    0.109</td> <td>    0.983</td> <td> 0.326</td> <td>   -0.107</td> <td>    0.321</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x100</th>  <td>    0.1145</td> <td>    0.109</td> <td>    1.052</td> <td> 0.293</td> <td>   -0.099</td> <td>    0.328</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x101</th>  <td>   -0.1893</td> <td>    0.126</td> <td>   -1.501</td> <td> 0.133</td> <td>   -0.437</td> <td>    0.058</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x102</th>  <td>   -0.2211</td> <td>    0.126</td> <td>   -1.752</td> <td> 0.080</td> <td>   -0.469</td> <td>    0.026</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x103</th>  <td>   -0.0103</td> <td>    0.092</td> <td>   -0.112</td> <td> 0.910</td> <td>   -0.190</td> <td>    0.169</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x104</th>  <td>   -0.0222</td> <td>    0.089</td> <td>   -0.250</td> <td> 0.803</td> <td>   -0.197</td> <td>    0.152</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x105</th>  <td>    0.1147</td> <td>    0.126</td> <td>    0.911</td> <td> 0.362</td> <td>   -0.132</td> <td>    0.361</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x106</th>  <td>    0.0748</td> <td>    0.124</td> <td>    0.605</td> <td> 0.545</td> <td>   -0.168</td> <td>    0.317</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x107</th>  <td>    0.2229</td> <td>    0.145</td> <td>    1.538</td> <td> 0.124</td> <td>   -0.061</td> <td>    0.507</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x108</th>  <td>    0.1872</td> <td>    0.143</td> <td>    1.307</td> <td> 0.191</td> <td>   -0.094</td> <td>    0.468</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x109</th>  <td>   -0.3388</td> <td>    0.147</td> <td>   -2.305</td> <td> 0.021</td> <td>   -0.627</td> <td>   -0.051</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x110</th>  <td>   -0.2798</td> <td>    0.144</td> <td>   -1.947</td> <td> 0.052</td> <td>   -0.561</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x111</th>  <td>    0.2237</td> <td>    0.193</td> <td>    1.159</td> <td> 0.246</td> <td>   -0.155</td> <td>    0.602</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x112</th>  <td>    0.2097</td> <td>    0.184</td> <td>    1.139</td> <td> 0.255</td> <td>   -0.151</td> <td>    0.571</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x113</th>  <td>   -0.1959</td> <td>    0.156</td> <td>   -1.253</td> <td> 0.210</td> <td>   -0.502</td> <td>    0.110</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x114</th>  <td>   -0.1904</td> <td>    0.145</td> <td>   -1.312</td> <td> 0.190</td> <td>   -0.475</td> <td>    0.094</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x115</th>  <td>   -0.0435</td> <td>    0.113</td> <td>   -0.386</td> <td> 0.700</td> <td>   -0.264</td> <td>    0.177</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x116</th>  <td>   -0.0202</td> <td>    0.110</td> <td>   -0.184</td> <td> 0.854</td> <td>   -0.235</td> <td>    0.195</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x117</th>  <td>   -2.0340</td> <td>    2.422</td> <td>   -0.840</td> <td> 0.401</td> <td>   -6.782</td> <td>    2.714</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x118</th>  <td>   -0.2062</td> <td>    0.298</td> <td>   -0.691</td> <td> 0.490</td> <td>   -0.791</td> <td>    0.379</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x119</th>  <td>   -1.5753</td> <td>    1.578</td> <td>   -0.998</td> <td> 0.318</td> <td>   -4.669</td> <td>    1.519</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x120</th>  <td>   -0.2848</td> <td>    0.206</td> <td>   -1.380</td> <td> 0.168</td> <td>   -0.689</td> <td>    0.120</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x121</th>  <td>    0.7614</td> <td>    2.267</td> <td>    0.336</td> <td> 0.737</td> <td>   -3.683</td> <td>    5.205</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x122</th>  <td>    0.1020</td> <td>    0.299</td> <td>    0.341</td> <td> 0.733</td> <td>   -0.485</td> <td>    0.689</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x123</th>  <td>    4.6824</td> <td>    2.414</td> <td>    1.940</td> <td> 0.052</td> <td>   -0.050</td> <td>    9.415</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x124</th>  <td>    0.5774</td> <td>    0.285</td> <td>    2.027</td> <td> 0.043</td> <td>    0.019</td> <td>    1.136</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x125</th>  <td>   -2.2436</td> <td>    2.747</td> <td>   -0.817</td> <td> 0.414</td> <td>   -7.627</td> <td>    3.140</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x126</th>  <td>   -0.1512</td> <td>    0.247</td> <td>   -0.613</td> <td> 0.540</td> <td>   -0.635</td> <td>    0.332</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x127</th>  <td>   -2.5209</td> <td>    2.188</td> <td>   -1.152</td> <td> 0.249</td> <td>   -6.810</td> <td>    1.768</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x128</th>  <td>   -0.3272</td> <td>    0.260</td> <td>   -1.257</td> <td> 0.209</td> <td>   -0.837</td> <td>    0.183</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x129</th>  <td>    3.3387</td> <td>    2.791</td> <td>    1.196</td> <td> 0.232</td> <td>   -2.132</td> <td>    8.810</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x130</th>  <td>    0.3136</td> <td>    0.230</td> <td>    1.366</td> <td> 0.172</td> <td>   -0.136</td> <td>    0.764</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x131</th>  <td>   -0.0561</td> <td>    0.194</td> <td>   -0.290</td> <td> 0.772</td> <td>   -0.435</td> <td>    0.323</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x132</th>  <td>   -0.0672</td> <td>    0.192</td> <td>   -0.350</td> <td> 0.727</td> <td>   -0.444</td> <td>    0.310</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x133</th>  <td>   -0.0648</td> <td>    0.037</td> <td>   -1.741</td> <td> 0.082</td> <td>   -0.138</td> <td>    0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x134</th>  <td>    0.0548</td> <td>    0.032</td> <td>    1.691</td> <td> 0.091</td> <td>   -0.009</td> <td>    0.118</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x135</th>  <td>    0.0590</td> <td>    0.033</td> <td>    1.814</td> <td> 0.070</td> <td>   -0.005</td> <td>    0.123</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x136</th>  <td>    0.0256</td> <td>    0.031</td> <td>    0.816</td> <td> 0.415</td> <td>   -0.036</td> <td>    0.087</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x137</th>  <td>    0.0411</td> <td>    0.036</td> <td>    1.131</td> <td> 0.258</td> <td>   -0.030</td> <td>    0.112</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x138</th>  <td>   -0.0332</td> <td>    0.034</td> <td>   -0.962</td> <td> 0.336</td> <td>   -0.101</td> <td>    0.034</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x139</th>  <td>   -0.0482</td> <td>    0.038</td> <td>   -1.284</td> <td> 0.199</td> <td>   -0.122</td> <td>    0.025</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x140</th>  <td>    0.0583</td> <td>    0.034</td> <td>    1.718</td> <td> 0.086</td> <td>   -0.008</td> <td>    0.125</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x141</th>  <td>   -0.0579</td> <td>    0.036</td> <td>   -1.619</td> <td> 0.106</td> <td>   -0.128</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x142</th>  <td>    0.0419</td> <td>    0.036</td> <td>    1.148</td> <td> 0.251</td> <td>   -0.030</td> <td>    0.113</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x143</th>  <td>   -0.0226</td> <td>    0.036</td> <td>   -0.631</td> <td> 0.528</td> <td>   -0.093</td> <td>    0.048</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x144</th>  <td>   -0.0504</td> <td>    0.032</td> <td>   -1.570</td> <td> 0.117</td> <td>   -0.113</td> <td>    0.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x145</th>  <td>    0.0415</td> <td>    0.036</td> <td>    1.143</td> <td> 0.253</td> <td>   -0.030</td> <td>    0.113</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x146</th>  <td>   -0.0201</td> <td>    0.033</td> <td>   -0.601</td> <td> 0.548</td> <td>   -0.086</td> <td>    0.045</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x147</th>  <td>    0.0659</td> <td>    0.034</td> <td>    1.966</td> <td> 0.049</td> <td>    0.000</td> <td>    0.132</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x148</th>  <td>   -0.0563</td> <td>    0.033</td> <td>   -1.693</td> <td> 0.090</td> <td>   -0.122</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x149</th>  <td>   -0.0655</td> <td>    0.033</td> <td>   -1.975</td> <td> 0.048</td> <td>   -0.131</td> <td>   -0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x150</th>  <td>   -0.0096</td> <td>    0.040</td> <td>   -0.242</td> <td> 0.809</td> <td>   -0.088</td> <td>    0.068</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x151</th>  <td>    0.0223</td> <td>    0.036</td> <td>    0.619</td> <td> 0.536</td> <td>   -0.048</td> <td>    0.093</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x152</th>  <td>    0.0169</td> <td>    0.033</td> <td>    0.505</td> <td> 0.614</td> <td>   -0.049</td> <td>    0.082</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x153</th>  <td>   -0.0944</td> <td>    0.032</td> <td>   -2.990</td> <td> 0.003</td> <td>   -0.156</td> <td>   -0.032</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x154</th>  <td>    0.0266</td> <td>    0.034</td> <td>    0.789</td> <td> 0.430</td> <td>   -0.040</td> <td>    0.093</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x155</th>  <td>   -0.0028</td> <td>    0.036</td> <td>   -0.076</td> <td> 0.939</td> <td>   -0.074</td> <td>    0.068</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x156</th>  <td>    0.0196</td> <td>    0.033</td> <td>    0.592</td> <td> 0.554</td> <td>   -0.045</td> <td>    0.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x157</th>  <td>    0.0768</td> <td>    0.033</td> <td>    2.362</td> <td> 0.018</td> <td>    0.013</td> <td>    0.141</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x158</th>  <td>   -0.0724</td> <td>    0.033</td> <td>   -2.219</td> <td> 0.026</td> <td>   -0.136</td> <td>   -0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x159</th>  <td>   -0.0224</td> <td>    0.032</td> <td>   -0.696</td> <td> 0.486</td> <td>   -0.085</td> <td>    0.041</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x160</th>  <td>    0.0056</td> <td>    0.034</td> <td>    0.166</td> <td> 0.868</td> <td>   -0.061</td> <td>    0.072</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x161</th>  <td>    0.0290</td> <td>    0.038</td> <td>    0.769</td> <td> 0.442</td> <td>   -0.045</td> <td>    0.103</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x162</th>  <td>   -0.1396</td> <td>    0.284</td> <td>   -0.491</td> <td> 0.623</td> <td>   -0.697</td> <td>    0.418</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x163</th>  <td>    0.3932</td> <td>    0.267</td> <td>    1.475</td> <td> 0.140</td> <td>   -0.129</td> <td>    0.916</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x164</th>  <td>   -0.1866</td> <td>    0.408</td> <td>   -0.458</td> <td> 0.647</td> <td>   -0.985</td> <td>    0.612</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x165</th>  <td>    0.1832</td> <td>    0.266</td> <td>    0.690</td> <td> 0.490</td> <td>   -0.338</td> <td>    0.704</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x166</th>  <td>    0.0044</td> <td>    0.277</td> <td>    0.016</td> <td> 0.987</td> <td>   -0.539</td> <td>    0.548</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x167</th>  <td>   -0.0195</td> <td>    0.246</td> <td>   -0.079</td> <td> 0.937</td> <td>   -0.503</td> <td>    0.463</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x168</th>  <td>    0.1079</td> <td>    0.385</td> <td>    0.280</td> <td> 0.779</td> <td>   -0.646</td> <td>    0.862</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x169</th>  <td>    0.2771</td> <td>    0.259</td> <td>    1.071</td> <td> 0.284</td> <td>   -0.230</td> <td>    0.785</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x170</th>  <td>   -0.1742</td> <td>    0.274</td> <td>   -0.635</td> <td> 0.526</td> <td>   -0.712</td> <td>    0.364</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x171</th>  <td>   -0.1424</td> <td>    0.253</td> <td>   -0.562</td> <td> 0.574</td> <td>   -0.639</td> <td>    0.354</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x172</th>  <td>    0.4825</td> <td>    0.342</td> <td>    1.412</td> <td> 0.158</td> <td>   -0.187</td> <td>    1.152</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x173</th>  <td>   -0.1215</td> <td>    0.268</td> <td>   -0.453</td> <td> 0.650</td> <td>   -0.647</td> <td>    0.404</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x174</th>  <td>    0.1018</td> <td>    0.273</td> <td>    0.372</td> <td> 0.710</td> <td>   -0.434</td> <td>    0.638</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x175</th>  <td>   -0.3053</td> <td>    0.460</td> <td>   -0.664</td> <td> 0.507</td> <td>   -1.207</td> <td>    0.596</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x176</th>  <td>    0.2235</td> <td>    0.449</td> <td>    0.498</td> <td> 0.618</td> <td>   -0.656</td> <td>    1.103</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x177</th>  <td>    0.1272</td> <td>    0.270</td> <td>    0.471</td> <td> 0.638</td> <td>   -0.402</td> <td>    0.656</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x178</th>  <td>    0.0689</td> <td>    0.280</td> <td>    0.246</td> <td> 0.806</td> <td>   -0.480</td> <td>    0.618</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x179</th>  <td>   -0.0077</td> <td>    0.330</td> <td>   -0.023</td> <td> 0.982</td> <td>   -0.655</td> <td>    0.640</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x180</th>  <td>    0.5053</td> <td>    0.373</td> <td>    1.353</td> <td> 0.176</td> <td>   -0.227</td> <td>    1.237</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x181</th>  <td>    0.1396</td> <td>    0.266</td> <td>    0.525</td> <td> 0.600</td> <td>   -0.382</td> <td>    0.661</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x182</th>  <td>   -0.3147</td> <td>    0.265</td> <td>   -1.189</td> <td> 0.235</td> <td>   -0.833</td> <td>    0.204</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x183</th>  <td>   -0.3819</td> <td>    0.489</td> <td>   -0.780</td> <td> 0.435</td> <td>   -1.341</td> <td>    0.577</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x184</th>  <td>   -0.9383</td> <td>    0.835</td> <td>   -1.123</td> <td> 0.261</td> <td>   -2.576</td> <td>    0.699</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x185</th>  <td>   -0.2065</td> <td>    0.396</td> <td>   -0.521</td> <td> 0.602</td> <td>   -0.983</td> <td>    0.570</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x186</th>  <td>    0.0791</td> <td>    0.725</td> <td>    0.109</td> <td> 0.913</td> <td>   -1.341</td> <td>    1.500</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x187</th>  <td>    0.0965</td> <td>    0.300</td> <td>    0.322</td> <td> 0.747</td> <td>   -0.491</td> <td>    0.684</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x188</th>  <td>   -0.1669</td> <td>    0.288</td> <td>   -0.580</td> <td> 0.562</td> <td>   -0.731</td> <td>    0.397</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x189</th>  <td>    0.0140</td> <td>    0.038</td> <td>    0.363</td> <td> 0.716</td> <td>   -0.061</td> <td>    0.089</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x190</th>  <td>    0.0030</td> <td>    0.029</td> <td>    0.105</td> <td> 0.916</td> <td>   -0.053</td> <td>    0.059</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x191</th>  <td>    0.1306</td> <td>    0.244</td> <td>    0.536</td> <td> 0.592</td> <td>   -0.347</td> <td>    0.608</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x192</th>  <td>    0.1303</td> <td>    0.118</td> <td>    1.103</td> <td> 0.270</td> <td>   -0.101</td> <td>    0.362</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x193</th>  <td>    0.0811</td> <td>    0.069</td> <td>    1.169</td> <td> 0.242</td> <td>   -0.055</td> <td>    0.217</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x194</th>  <td>   -0.0194</td> <td>    0.143</td> <td>   -0.135</td> <td> 0.892</td> <td>   -0.301</td> <td>    0.262</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x195</th>  <td>   -0.0819</td> <td>    0.259</td> <td>   -0.316</td> <td> 0.752</td> <td>   -0.590</td> <td>    0.426</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x196</th>  <td>   -0.0507</td> <td>    0.077</td> <td>   -0.660</td> <td> 0.510</td> <td>   -0.201</td> <td>    0.100</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x197</th>  <td>   -0.4266</td> <td>    0.178</td> <td>   -2.402</td> <td> 0.016</td> <td>   -0.775</td> <td>   -0.079</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x198</th>  <td>    0.3961</td> <td>    0.173</td> <td>    2.296</td> <td> 0.022</td> <td>    0.058</td> <td>    0.734</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x199</th>  <td>   -0.1117</td> <td>    0.075</td> <td>   -1.484</td> <td> 0.138</td> <td>   -0.259</td> <td>    0.036</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x200</th>  <td>    0.0460</td> <td>    0.179</td> <td>    0.257</td> <td> 0.797</td> <td>   -0.305</td> <td>    0.397</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x201</th>  <td>    0.0764</td> <td>    0.169</td> <td>    0.452</td> <td> 0.652</td> <td>   -0.255</td> <td>    0.408</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x202</th>  <td>   -0.1859</td> <td>    0.066</td> <td>   -2.823</td> <td> 0.005</td> <td>   -0.315</td> <td>   -0.057</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x203</th>  <td>    0.2124</td> <td>    0.075</td> <td>    2.818</td> <td> 0.005</td> <td>    0.065</td> <td>    0.360</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x204</th>  <td>   -0.0025</td> <td>    0.071</td> <td>   -0.035</td> <td> 0.972</td> <td>   -0.141</td> <td>    0.136</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x205</th>  <td>   -0.0076</td> <td>    0.038</td> <td>   -0.202</td> <td> 0.840</td> <td>   -0.081</td> <td>    0.066</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x206</th>  <td>    0.6316</td> <td>    0.304</td> <td>    2.076</td> <td> 0.038</td> <td>    0.035</td> <td>    1.228</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x207</th>  <td>   -0.0849</td> <td>    0.075</td> <td>   -1.128</td> <td> 0.259</td> <td>   -0.232</td> <td>    0.063</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x208</th>  <td>    0.1313</td> <td>    0.145</td> <td>    0.904</td> <td> 0.366</td> <td>   -0.153</td> <td>    0.416</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x209</th>  <td>   -0.6279</td> <td>    0.254</td> <td>   -2.475</td> <td> 0.013</td> <td>   -1.125</td> <td>   -0.131</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x210</th>  <td>   -0.0219</td> <td>    0.086</td> <td>   -0.255</td> <td> 0.799</td> <td>   -0.190</td> <td>    0.146</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x211</th>  <td>    0.3414</td> <td>    0.167</td> <td>    2.048</td> <td> 0.041</td> <td>    0.015</td> <td>    0.668</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x212</th>  <td>   -0.3734</td> <td>    0.171</td> <td>   -2.178</td> <td> 0.029</td> <td>   -0.709</td> <td>   -0.037</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x213</th>  <td>    0.0985</td> <td>    0.091</td> <td>    1.087</td> <td> 0.277</td> <td>   -0.079</td> <td>    0.276</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x214</th>  <td>    0.0444</td> <td>    0.188</td> <td>    0.236</td> <td> 0.813</td> <td>   -0.324</td> <td>    0.413</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x215</th>  <td>   -0.2225</td> <td>    0.172</td> <td>   -1.292</td> <td> 0.196</td> <td>   -0.560</td> <td>    0.115</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x216</th>  <td>    0.2998</td> <td>    0.078</td> <td>    3.828</td> <td> 0.000</td> <td>    0.146</td> <td>    0.453</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x217</th>  <td>   -0.2741</td> <td>    0.082</td> <td>   -3.328</td> <td> 0.001</td> <td>   -0.436</td> <td>   -0.113</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x218</th>  <td>   -0.0369</td> <td>    0.035</td> <td>   -1.042</td> <td> 0.297</td> <td>   -0.106</td> <td>    0.033</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x219</th>  <td>   -0.0323</td> <td>    0.035</td> <td>   -0.911</td> <td> 0.362</td> <td>   -0.102</td> <td>    0.037</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x220</th>  <td>    0.0274</td> <td>    0.065</td> <td>    0.422</td> <td> 0.673</td> <td>   -0.100</td> <td>    0.155</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x221</th>  <td>    0.0621</td> <td>    0.034</td> <td>    1.826</td> <td> 0.068</td> <td>   -0.005</td> <td>    0.129</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x222</th>  <td>    0.0398</td> <td>    0.076</td> <td>    0.520</td> <td> 0.603</td> <td>   -0.110</td> <td>    0.190</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x223</th>  <td>   -0.0584</td> <td>    0.075</td> <td>   -0.775</td> <td> 0.439</td> <td>   -0.206</td> <td>    0.089</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x224</th>  <td>    0.0284</td> <td>    0.064</td> <td>    0.441</td> <td> 0.659</td> <td>   -0.098</td> <td>    0.155</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x225</th>  <td>   -0.0917</td> <td>    0.070</td> <td>   -1.304</td> <td> 0.192</td> <td>   -0.230</td> <td>    0.046</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x226</th>  <td>    0.0164</td> <td>    0.064</td> <td>    0.254</td> <td> 0.799</td> <td>   -0.110</td> <td>    0.143</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x227</th>  <td>    0.0949</td> <td>    0.069</td> <td>    1.368</td> <td> 0.171</td> <td>   -0.041</td> <td>    0.231</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x228</th>  <td>    0.0082</td> <td>    0.082</td> <td>    0.101</td> <td> 0.920</td> <td>   -0.152</td> <td>    0.168</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x229</th>  <td>    0.0674</td> <td>    0.071</td> <td>    0.955</td> <td> 0.339</td> <td>   -0.071</td> <td>    0.206</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x230</th>  <td>    0.0057</td> <td>    0.067</td> <td>    0.085</td> <td> 0.932</td> <td>   -0.125</td> <td>    0.137</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x231</th>  <td>    0.1453</td> <td>    0.073</td> <td>    2.003</td> <td> 0.045</td> <td>    0.003</td> <td>    0.287</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x232</th>  <td>    0.0736</td> <td>    0.076</td> <td>    0.972</td> <td> 0.331</td> <td>   -0.075</td> <td>    0.222</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x233</th>  <td>   -0.0668</td> <td>    0.088</td> <td>   -0.757</td> <td> 0.449</td> <td>   -0.240</td> <td>    0.106</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x234</th>  <td>   -0.1196</td> <td>    0.085</td> <td>   -1.412</td> <td> 0.158</td> <td>   -0.286</td> <td>    0.046</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x235</th>  <td>   -0.0073</td> <td>    0.081</td> <td>   -0.090</td> <td> 0.928</td> <td>   -0.167</td> <td>    0.152</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x236</th>  <td>   -0.0181</td> <td>    0.068</td> <td>   -0.266</td> <td> 0.791</td> <td>   -0.151</td> <td>    0.115</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x237</th>  <td>   -0.0008</td> <td>    0.071</td> <td>   -0.011</td> <td> 0.991</td> <td>   -0.141</td> <td>    0.139</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x238</th>  <td>   -0.1415</td> <td>    0.085</td> <td>   -1.658</td> <td> 0.097</td> <td>   -0.309</td> <td>    0.026</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x239</th>  <td>    0.0516</td> <td>    0.080</td> <td>    0.643</td> <td> 0.520</td> <td>   -0.106</td> <td>    0.209</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x240</th>  <td>   -0.0021</td> <td>    0.053</td> <td>   -0.040</td> <td> 0.968</td> <td>   -0.106</td> <td>    0.102</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x241</th>  <td>   -0.0265</td> <td>    0.034</td> <td>   -0.781</td> <td> 0.435</td> <td>   -0.093</td> <td>    0.040</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x242</th>  <td>    0.0128</td> <td>    0.068</td> <td>    0.188</td> <td> 0.851</td> <td>   -0.121</td> <td>    0.147</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x243</th>  <td>   -0.0784</td> <td>    0.059</td> <td>   -1.328</td> <td> 0.184</td> <td>   -0.194</td> <td>    0.037</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x244</th>  <td>   -0.0607</td> <td>    0.049</td> <td>   -1.242</td> <td> 0.214</td> <td>   -0.157</td> <td>    0.035</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x245</th>  <td>   -0.0481</td> <td>    0.056</td> <td>   -0.862</td> <td> 0.389</td> <td>   -0.158</td> <td>    0.061</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x246</th>  <td>   -0.0029</td> <td>    0.049</td> <td>   -0.058</td> <td> 0.954</td> <td>   -0.099</td> <td>    0.094</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x247</th>  <td>   -0.0024</td> <td>    0.061</td> <td>   -0.040</td> <td> 0.968</td> <td>   -0.122</td> <td>    0.118</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x248</th>  <td>    0.0184</td> <td>    0.070</td> <td>    0.264</td> <td> 0.792</td> <td>   -0.118</td> <td>    0.155</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x249</th>  <td>   -0.0145</td> <td>    0.055</td> <td>   -0.261</td> <td> 0.794</td> <td>   -0.123</td> <td>    0.094</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x250</th>  <td>    0.0032</td> <td>    0.053</td> <td>    0.061</td> <td> 0.951</td> <td>   -0.100</td> <td>    0.107</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x251</th>  <td>   -0.0052</td> <td>    0.057</td> <td>   -0.091</td> <td> 0.927</td> <td>   -0.117</td> <td>    0.107</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x252</th>  <td>   -0.0219</td> <td>    0.056</td> <td>   -0.391</td> <td> 0.696</td> <td>   -0.131</td> <td>    0.088</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x253</th>  <td>    0.0349</td> <td>    0.068</td> <td>    0.514</td> <td> 0.607</td> <td>   -0.098</td> <td>    0.168</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x254</th>  <td>    0.1182</td> <td>    0.071</td> <td>    1.675</td> <td> 0.094</td> <td>   -0.020</td> <td>    0.257</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x255</th>  <td>    0.0280</td> <td>    0.061</td> <td>    0.462</td> <td> 0.644</td> <td>   -0.091</td> <td>    0.147</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x256</th>  <td>   -0.1019</td> <td>    0.054</td> <td>   -1.875</td> <td> 0.061</td> <td>   -0.208</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x257</th>  <td>    0.0787</td> <td>    0.056</td> <td>    1.408</td> <td> 0.159</td> <td>   -0.031</td> <td>    0.188</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x258</th>  <td>    0.0361</td> <td>    0.059</td> <td>    0.612</td> <td> 0.541</td> <td>   -0.080</td> <td>    0.152</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x259</th>  <td>   -0.0100</td> <td>    0.056</td> <td>   -0.176</td> <td> 0.860</td> <td>   -0.121</td> <td>    0.101</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x260</th>  <td>   -0.0427</td> <td>    0.030</td> <td>   -1.432</td> <td> 0.152</td> <td>   -0.101</td> <td>    0.016</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x261</th>  <td>    0.0077</td> <td>    0.031</td> <td>    0.245</td> <td> 0.806</td> <td>   -0.054</td> <td>    0.069</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x262</th>  <td>    0.0223</td> <td>    0.030</td> <td>    0.736</td> <td> 0.462</td> <td>   -0.037</td> <td>    0.082</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x263</th>  <td>    0.0334</td> <td>    0.031</td> <td>    1.080</td> <td> 0.280</td> <td>   -0.027</td> <td>    0.094</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x264</th>  <td>   -0.0248</td> <td>    0.031</td> <td>   -0.806</td> <td> 0.420</td> <td>   -0.085</td> <td>    0.036</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x265</th>  <td>    0.0287</td> <td>    0.033</td> <td>    0.868</td> <td> 0.385</td> <td>   -0.036</td> <td>    0.094</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x266</th>  <td>    0.0159</td> <td>    0.048</td> <td>    0.330</td> <td> 0.742</td> <td>   -0.079</td> <td>    0.110</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x267</th>  <td>    0.0559</td> <td>    0.050</td> <td>    1.127</td> <td> 0.260</td> <td>   -0.041</td> <td>    0.153</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x268</th>  <td>   -0.0436</td> <td>    0.041</td> <td>   -1.054</td> <td> 0.292</td> <td>   -0.125</td> <td>    0.037</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x269</th>  <td>    0.0061</td> <td>    0.034</td> <td>    0.179</td> <td> 0.858</td> <td>   -0.060</td> <td>    0.073</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x270</th>  <td>    0.0194</td> <td>    0.026</td> <td>    0.761</td> <td> 0.446</td> <td>   -0.031</td> <td>    0.069</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x271</th>  <td>    0.0926</td> <td>    0.030</td> <td>    3.082</td> <td> 0.002</td> <td>    0.034</td> <td>    0.151</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x272</th>  <td>   -0.0033</td> <td>    0.030</td> <td>   -0.111</td> <td> 0.912</td> <td>   -0.063</td> <td>    0.056</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x273</th>  <td>   -0.0290</td> <td>    0.028</td> <td>   -1.039</td> <td> 0.299</td> <td>   -0.084</td> <td>    0.026</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x274</th>  <td>    0.0250</td> <td>    0.032</td> <td>    0.781</td> <td> 0.435</td> <td>   -0.038</td> <td>    0.088</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x275</th>  <td>   -0.1156</td> <td>    0.028</td> <td>   -4.070</td> <td> 0.000</td> <td>   -0.171</td> <td>   -0.060</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x276</th>  <td>   -0.0920</td> <td>    0.028</td> <td>   -3.273</td> <td> 0.001</td> <td>   -0.147</td> <td>   -0.037</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x277</th>  <td>    0.8102</td> <td>    0.033</td> <td>   24.592</td> <td> 0.000</td> <td>    0.746</td> <td>    0.875</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x278</th>  <td>   -0.0127</td> <td>    0.033</td> <td>   -0.380</td> <td> 0.704</td> <td>   -0.078</td> <td>    0.053</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x279</th>  <td>   -0.0564</td> <td>    0.029</td> <td>   -1.931</td> <td> 0.054</td> <td>   -0.114</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x280</th>  <td>   -0.0137</td> <td>    0.030</td> <td>   -0.454</td> <td> 0.650</td> <td>   -0.073</td> <td>    0.046</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x281</th>  <td>   -0.0169</td> <td>    0.033</td> <td>   -0.518</td> <td> 0.604</td> <td>   -0.081</td> <td>    0.047</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x282</th>  <td>    0.0280</td> <td>    0.029</td> <td>    0.974</td> <td> 0.330</td> <td>   -0.028</td> <td>    0.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x283</th>  <td>   -0.0094</td> <td>    0.027</td> <td>   -0.353</td> <td> 0.724</td> <td>   -0.061</td> <td>    0.043</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x284</th>  <td>   -0.0165</td> <td>    0.025</td> <td>   -0.649</td> <td> 0.516</td> <td>   -0.066</td> <td>    0.033</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x285</th>  <td>    0.0020</td> <td>    0.026</td> <td>    0.076</td> <td> 0.939</td> <td>   -0.050</td> <td>    0.054</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x286</th>  <td>   -0.0049</td> <td>    0.027</td> <td>   -0.185</td> <td> 0.853</td> <td>   -0.057</td> <td>    0.047</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x287</th>  <td>    0.0104</td> <td>    0.027</td> <td>    0.387</td> <td> 0.699</td> <td>   -0.042</td> <td>    0.063</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x288</th>  <td>    0.0192</td> <td>    0.028</td> <td>    0.673</td> <td> 0.501</td> <td>   -0.037</td> <td>    0.075</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x289</th>  <td>   -0.0227</td> <td>    0.025</td> <td>   -0.893</td> <td> 0.372</td> <td>   -0.073</td> <td>    0.027</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x290</th>  <td>    0.0558</td> <td>    0.026</td> <td>    2.172</td> <td> 0.030</td> <td>    0.005</td> <td>    0.106</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x291</th>  <td>    0.0368</td> <td>    0.027</td> <td>    1.355</td> <td> 0.176</td> <td>   -0.016</td> <td>    0.090</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x292</th>  <td>   -0.0151</td> <td>    0.039</td> <td>   -0.384</td> <td> 0.701</td> <td>   -0.092</td> <td>    0.062</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x293</th>  <td>    0.0065</td> <td>    0.043</td> <td>    0.151</td> <td> 0.880</td> <td>   -0.078</td> <td>    0.091</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x294</th>  <td>    0.0074</td> <td>    0.042</td> <td>    0.178</td> <td> 0.858</td> <td>   -0.074</td> <td>    0.089</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x295</th>  <td>    0.0070</td> <td>    0.037</td> <td>    0.190</td> <td> 0.850</td> <td>   -0.066</td> <td>    0.080</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x296</th>  <td>    0.0142</td> <td>    0.037</td> <td>    0.382</td> <td> 0.703</td> <td>   -0.059</td> <td>    0.087</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x297</th>  <td>   -0.0258</td> <td>    0.036</td> <td>   -0.713</td> <td> 0.476</td> <td>   -0.097</td> <td>    0.045</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x298</th>  <td>   -0.0197</td> <td>    0.037</td> <td>   -0.532</td> <td> 0.595</td> <td>   -0.092</td> <td>    0.053</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x299</th>  <td>   -0.0010</td> <td>    0.040</td> <td>   -0.026</td> <td> 0.979</td> <td>   -0.080</td> <td>    0.078</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x300</th>  <td>    0.0550</td> <td>    0.036</td> <td>    1.536</td> <td> 0.125</td> <td>   -0.015</td> <td>    0.125</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x301</th>  <td>   -2.1638</td> <td>    0.044</td> <td>  -49.112</td> <td> 0.000</td> <td>   -2.250</td> <td>   -2.077</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x302</th>  <td>    0.1656</td> <td>    0.040</td> <td>    4.136</td> <td> 0.000</td> <td>    0.087</td> <td>    0.244</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x303</th>  <td>   -0.1838</td> <td>    0.030</td> <td>   -6.109</td> <td> 0.000</td> <td>   -0.243</td> <td>   -0.125</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x304</th>  <td>    0.3516</td> <td>    0.039</td> <td>    9.124</td> <td> 0.000</td> <td>    0.276</td> <td>    0.427</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x305</th>  <td>   -0.0741</td> <td>    0.035</td> <td>   -2.106</td> <td> 0.035</td> <td>   -0.143</td> <td>   -0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x306</th>  <td>    0.0313</td> <td>    0.029</td> <td>    1.073</td> <td> 0.283</td> <td>   -0.026</td> <td>    0.088</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x307</th>  <td>   -0.0290</td> <td>    0.028</td> <td>   -1.026</td> <td> 0.305</td> <td>   -0.084</td> <td>    0.026</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x308</th>  <td>    0.0016</td> <td>    0.028</td> <td>    0.060</td> <td> 0.952</td> <td>   -0.052</td> <td>    0.056</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x309</th>  <td>    0.0019</td> <td>    0.105</td> <td>    0.018</td> <td> 0.986</td> <td>   -0.204</td> <td>    0.208</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x310</th>  <td>   -0.0296</td> <td>    0.081</td> <td>   -0.366</td> <td> 0.714</td> <td>   -0.188</td> <td>    0.129</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x311</th>  <td>    0.0688</td> <td>    0.046</td> <td>    1.512</td> <td> 0.131</td> <td>   -0.020</td> <td>    0.158</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x312</th>  <td>   -0.0211</td> <td>    0.042</td> <td>   -0.508</td> <td> 0.611</td> <td>   -0.103</td> <td>    0.060</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x313</th>  <td>    0.0186</td> <td>    0.030</td> <td>    0.621</td> <td> 0.534</td> <td>   -0.040</td> <td>    0.077</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x314</th>  <td>    0.0560</td> <td>    0.071</td> <td>    0.794</td> <td> 0.427</td> <td>   -0.082</td> <td>    0.194</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x315</th>  <td>   -0.0811</td> <td>    0.059</td> <td>   -1.381</td> <td> 0.167</td> <td>   -0.196</td> <td>    0.034</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x316</th>  <td>    0.0281</td> <td>    0.032</td> <td>    0.876</td> <td> 0.381</td> <td>   -0.035</td> <td>    0.091</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x317</th>  <td>   -0.0255</td> <td>    0.031</td> <td>   -0.817</td> <td> 0.414</td> <td>   -0.087</td> <td>    0.036</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x318</th>  <td>   -0.0393</td> <td>    0.031</td> <td>   -1.286</td> <td> 0.199</td> <td>   -0.099</td> <td>    0.021</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x319</th>  <td>   -0.0509</td> <td>    0.030</td> <td>   -1.679</td> <td> 0.093</td> <td>   -0.110</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x320</th>  <td>    0.0223</td> <td>    0.060</td> <td>    0.374</td> <td> 0.708</td> <td>   -0.095</td> <td>    0.139</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x321</th>  <td>   -0.0104</td> <td>    0.062</td> <td>   -0.167</td> <td> 0.868</td> <td>   -0.132</td> <td>    0.112</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x322</th>  <td>   -0.0762</td> <td>    0.055</td> <td>   -1.392</td> <td> 0.164</td> <td>   -0.184</td> <td>    0.031</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x323</th>  <td>    0.0348</td> <td>    0.060</td> <td>    0.585</td> <td> 0.558</td> <td>   -0.082</td> <td>    0.151</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x324</th>  <td>    0.0186</td> <td>    0.033</td> <td>    0.559</td> <td> 0.576</td> <td>   -0.047</td> <td>    0.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x325</th>  <td>   -0.0102</td> <td>    0.032</td> <td>   -0.317</td> <td> 0.751</td> <td>   -0.074</td> <td>    0.053</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x326</th>  <td>   -0.0330</td> <td>    0.029</td> <td>   -1.138</td> <td> 0.255</td> <td>   -0.090</td> <td>    0.024</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x327</th>  <td>   -0.0269</td> <td>    0.030</td> <td>   -0.897</td> <td> 0.370</td> <td>   -0.086</td> <td>    0.032</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x328</th>  <td>    0.0246</td> <td>    0.030</td> <td>    0.810</td> <td> 0.418</td> <td>   -0.035</td> <td>    0.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x329</th>  <td>   -0.0173</td> <td>    0.029</td> <td>   -0.603</td> <td> 0.546</td> <td>   -0.074</td> <td>    0.039</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x330</th>  <td>   -0.0353</td> <td>    0.143</td> <td>   -0.246</td> <td> 0.806</td> <td>   -0.317</td> <td>    0.246</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x331</th>  <td>    0.1126</td> <td>    0.055</td> <td>    2.044</td> <td> 0.041</td> <td>    0.005</td> <td>    0.220</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x332</th>  <td>    0.2919</td> <td>    0.221</td> <td>    1.319</td> <td> 0.187</td> <td>   -0.142</td> <td>    0.726</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x333</th>  <td>   -0.3300</td> <td>    0.230</td> <td>   -1.437</td> <td> 0.151</td> <td>   -0.780</td> <td>    0.120</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x334</th>  <td>   -0.1802</td> <td>    0.203</td> <td>   -0.887</td> <td> 0.375</td> <td>   -0.579</td> <td>    0.218</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x335</th>  <td>    0.1139</td> <td>    0.200</td> <td>    0.569</td> <td> 0.570</td> <td>   -0.279</td> <td>    0.507</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x336</th>  <td>   -0.1177</td> <td>    0.138</td> <td>   -0.854</td> <td> 0.393</td> <td>   -0.388</td> <td>    0.153</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x337</th>  <td>    0.0229</td> <td>    0.071</td> <td>    0.323</td> <td> 0.746</td> <td>   -0.116</td> <td>    0.162</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x338</th>  <td>    0.0886</td> <td>    0.057</td> <td>    1.542</td> <td> 0.123</td> <td>   -0.024</td> <td>    0.201</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x339</th>  <td>   -0.0352</td> <td>    0.049</td> <td>   -0.724</td> <td> 0.469</td> <td>   -0.130</td> <td>    0.060</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x340</th>  <td>    0.1585</td> <td>    0.102</td> <td>    1.559</td> <td> 0.119</td> <td>   -0.041</td> <td>    0.358</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x341</th>  <td>   -0.0573</td> <td>    0.089</td> <td>   -0.642</td> <td> 0.521</td> <td>   -0.232</td> <td>    0.118</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x342</th>  <td>   -0.4494</td> <td>    0.157</td> <td>   -2.870</td> <td> 0.004</td> <td>   -0.756</td> <td>   -0.142</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x343</th>  <td>   -0.0125</td> <td>    0.039</td> <td>   -0.320</td> <td> 0.749</td> <td>   -0.089</td> <td>    0.064</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x344</th>  <td>    0.0511</td> <td>    0.033</td> <td>    1.548</td> <td> 0.122</td> <td>   -0.014</td> <td>    0.116</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x345</th>  <td>    0.0045</td> <td>    0.028</td> <td>    0.162</td> <td> 0.871</td> <td>   -0.050</td> <td>    0.059</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x346</th>  <td>    0.0777</td> <td>    0.035</td> <td>    2.231</td> <td> 0.026</td> <td>    0.009</td> <td>    0.146</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x347</th>  <td>    0.0245</td> <td>    0.026</td> <td>    0.958</td> <td> 0.338</td> <td>   -0.026</td> <td>    0.075</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x348</th>  <td>    0.0769</td> <td>    0.026</td> <td>    2.992</td> <td> 0.003</td> <td>    0.027</td> <td>    0.127</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x349</th>  <td>    0.0231</td> <td>    0.071</td> <td>    0.327</td> <td> 0.744</td> <td>   -0.115</td> <td>    0.161</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x350</th>  <td>    0.1325</td> <td>    0.112</td> <td>    1.185</td> <td> 0.236</td> <td>   -0.087</td> <td>    0.352</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x351</th>  <td>   -0.0151</td> <td>    0.035</td> <td>   -0.432</td> <td> 0.666</td> <td>   -0.084</td> <td>    0.054</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x352</th>  <td>    0.0229</td> <td>    0.075</td> <td>    0.305</td> <td> 0.760</td> <td>   -0.124</td> <td>    0.170</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x353</th>  <td>    0.0831</td> <td>    0.066</td> <td>    1.265</td> <td> 0.206</td> <td>   -0.046</td> <td>    0.212</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x354</th>  <td>    0.2255</td> <td>    0.190</td> <td>    1.184</td> <td> 0.236</td> <td>   -0.148</td> <td>    0.599</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x355</th>  <td>   -0.2711</td> <td>    0.198</td> <td>   -1.372</td> <td> 0.170</td> <td>   -0.658</td> <td>    0.116</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x356</th>  <td>   -0.0508</td> <td>    0.047</td> <td>   -1.070</td> <td> 0.285</td> <td>   -0.144</td> <td>    0.042</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x357</th>  <td>    0.0045</td> <td>    0.074</td> <td>    0.061</td> <td> 0.952</td> <td>   -0.140</td> <td>    0.149</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x358</th>  <td>   -0.0490</td> <td>    0.073</td> <td>   -0.671</td> <td> 0.502</td> <td>   -0.192</td> <td>    0.094</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x359</th>  <td>    0.0365</td> <td>    0.267</td> <td>    0.137</td> <td> 0.891</td> <td>   -0.486</td> <td>    0.559</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x360</th>  <td>   -0.1348</td> <td>    0.261</td> <td>   -0.517</td> <td> 0.605</td> <td>   -0.646</td> <td>    0.376</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x361</th>  <td>    0.1159</td> <td>    0.285</td> <td>    0.407</td> <td> 0.684</td> <td>   -0.442</td> <td>    0.674</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x362</th>  <td>    0.1350</td> <td>    0.101</td> <td>    1.332</td> <td> 0.183</td> <td>   -0.064</td> <td>    0.334</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x363</th>  <td>   -0.0504</td> <td>    0.039</td> <td>   -1.302</td> <td> 0.193</td> <td>   -0.126</td> <td>    0.025</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x364</th>  <td>   -0.0398</td> <td>    0.060</td> <td>   -0.660</td> <td> 0.509</td> <td>   -0.158</td> <td>    0.078</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x365</th>  <td>   -0.0118</td> <td>    0.181</td> <td>   -0.066</td> <td> 0.948</td> <td>   -0.366</td> <td>    0.342</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x366</th>  <td>    0.0981</td> <td>    0.114</td> <td>    0.859</td> <td> 0.391</td> <td>   -0.126</td> <td>    0.322</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x367</th>  <td>    0.0406</td> <td>    0.045</td> <td>    0.904</td> <td> 0.366</td> <td>   -0.047</td> <td>    0.129</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x368</th>  <td>   -0.1987</td> <td>    0.221</td> <td>   -0.897</td> <td> 0.370</td> <td>   -0.633</td> <td>    0.235</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x369</th>  <td>    0.3236</td> <td>    0.163</td> <td>    1.989</td> <td> 0.047</td> <td>    0.005</td> <td>    0.643</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x370</th>  <td>   -0.3139</td> <td>    0.165</td> <td>   -1.905</td> <td> 0.057</td> <td>   -0.637</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x371</th>  <td>   -0.0762</td> <td>    0.039</td> <td>   -1.959</td> <td> 0.050</td> <td>   -0.152</td> <td> 4.56e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x372</th>  <td>    0.2329</td> <td>    0.188</td> <td>    1.241</td> <td> 0.215</td> <td>   -0.135</td> <td>    0.601</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x373</th>  <td>    0.0091</td> <td>    0.036</td> <td>    0.255</td> <td> 0.799</td> <td>   -0.061</td> <td>    0.079</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x374</th>  <td>    0.0311</td> <td>    0.232</td> <td>    0.134</td> <td> 0.893</td> <td>   -0.424</td> <td>    0.486</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x375</th>  <td>    0.0423</td> <td>    0.240</td> <td>    0.176</td> <td> 0.860</td> <td>   -0.428</td> <td>    0.512</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x376</th>  <td>    0.0058</td> <td>    0.167</td> <td>    0.035</td> <td> 0.972</td> <td>   -0.321</td> <td>    0.333</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x377</th>  <td>   -0.1670</td> <td>    0.085</td> <td>   -1.954</td> <td> 0.051</td> <td>   -0.335</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x378</th>  <td>    0.0226</td> <td>    0.027</td> <td>    0.840</td> <td> 0.401</td> <td>   -0.030</td> <td>    0.075</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x379</th>  <td>   -0.0341</td> <td>    0.026</td> <td>   -1.312</td> <td> 0.190</td> <td>   -0.085</td> <td>    0.017</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x380</th>  <td>   -0.0039</td> <td>    0.026</td> <td>   -0.148</td> <td> 0.882</td> <td>   -0.055</td> <td>    0.047</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x381</th>  <td>   -0.0194</td> <td>    0.026</td> <td>   -0.756</td> <td> 0.449</td> <td>   -0.070</td> <td>    0.031</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x382</th>  <td>   -0.0040</td> <td>    0.027</td> <td>   -0.152</td> <td> 0.880</td> <td>   -0.056</td> <td>    0.048</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x383</th>  <td>    0.0204</td> <td>    0.026</td> <td>    0.787</td> <td> 0.431</td> <td>   -0.030</td> <td>    0.071</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x384</th>  <td>   -0.0769</td> <td>    0.030</td> <td>   -2.585</td> <td> 0.010</td> <td>   -0.135</td> <td>   -0.019</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x385</th>  <td>   -0.0047</td> <td>    0.030</td> <td>   -0.157</td> <td> 0.875</td> <td>   -0.063</td> <td>    0.053</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x386</th>  <td>   -0.0283</td> <td>    0.027</td> <td>   -1.036</td> <td> 0.300</td> <td>   -0.082</td> <td>    0.025</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x387</th>  <td>   -0.0106</td> <td>    0.027</td> <td>   -0.391</td> <td> 0.696</td> <td>   -0.064</td> <td>    0.042</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x388</th>  <td>   -0.0312</td> <td>    0.036</td> <td>   -0.876</td> <td> 0.381</td> <td>   -0.101</td> <td>    0.039</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x389</th>  <td>   -0.0218</td> <td>    0.032</td> <td>   -0.676</td> <td> 0.499</td> <td>   -0.085</td> <td>    0.041</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x390</th>  <td>    0.0068</td> <td>    0.034</td> <td>    0.201</td> <td> 0.841</td> <td>   -0.060</td> <td>    0.074</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x391</th>  <td>   -0.0419</td> <td>    0.033</td> <td>   -1.256</td> <td> 0.209</td> <td>   -0.107</td> <td>    0.023</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x392</th>  <td>    0.0530</td> <td>    0.038</td> <td>    1.403</td> <td> 0.161</td> <td>   -0.021</td> <td>    0.127</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x393</th>  <td>   -0.0361</td> <td>    0.034</td> <td>   -1.077</td> <td> 0.281</td> <td>   -0.102</td> <td>    0.030</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x394</th>  <td>    0.0060</td> <td>    0.032</td> <td>    0.189</td> <td> 0.850</td> <td>   -0.056</td> <td>    0.068</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x395</th>  <td>    0.0103</td> <td>    0.032</td> <td>    0.321</td> <td> 0.748</td> <td>   -0.052</td> <td>    0.073</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x396</th>  <td>    0.0067</td> <td>    0.027</td> <td>    0.249</td> <td> 0.803</td> <td>   -0.046</td> <td>    0.060</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x397</th>  <td>   -0.0088</td> <td>    0.032</td> <td>   -0.277</td> <td> 0.782</td> <td>   -0.071</td> <td>    0.053</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x398</th>  <td>   -0.0041</td> <td>    0.033</td> <td>   -0.125</td> <td> 0.901</td> <td>   -0.068</td> <td>    0.060</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x399</th>  <td>    0.0484</td> <td>    0.031</td> <td>    1.559</td> <td> 0.119</td> <td>   -0.012</td> <td>    0.109</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x400</th>  <td>    0.0414</td> <td>    0.072</td> <td>    0.578</td> <td> 0.563</td> <td>   -0.099</td> <td>    0.182</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x401</th>  <td>    0.0589</td> <td>    0.073</td> <td>    0.811</td> <td> 0.417</td> <td>   -0.083</td> <td>    0.201</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x402</th>  <td>    0.0011</td> <td>    0.109</td> <td>    0.010</td> <td> 0.992</td> <td>   -0.213</td> <td>    0.216</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x403</th>  <td>   -0.0540</td> <td>    0.112</td> <td>   -0.482</td> <td> 0.630</td> <td>   -0.274</td> <td>    0.166</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x404</th>  <td>   -0.0241</td> <td>    0.036</td> <td>   -0.669</td> <td> 0.504</td> <td>   -0.095</td> <td>    0.046</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x405</th>  <td>    0.0096</td> <td>    0.027</td> <td>    0.358</td> <td> 0.720</td> <td>   -0.043</td> <td>    0.062</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x406</th>  <td>    0.0007</td> <td>    0.027</td> <td>    0.026</td> <td> 0.979</td> <td>   -0.052</td> <td>    0.054</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x407</th>  <td>    0.0003</td> <td>    0.040</td> <td>    0.008</td> <td> 0.994</td> <td>   -0.078</td> <td>    0.078</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x408</th>  <td>    0.0976</td> <td>    0.032</td> <td>    3.047</td> <td> 0.002</td> <td>    0.035</td> <td>    0.160</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x409</th>  <td>    0.0281</td> <td>    0.025</td> <td>    1.105</td> <td> 0.269</td> <td>   -0.022</td> <td>    0.078</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x410</th>  <td>    0.0114</td> <td>    0.028</td> <td>    0.408</td> <td> 0.683</td> <td>   -0.043</td> <td>    0.066</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x411</th>  <td>   -0.0514</td> <td>    0.027</td> <td>   -1.905</td> <td> 0.057</td> <td>   -0.104</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x412</th>  <td>    0.0032</td> <td>    0.026</td> <td>    0.124</td> <td> 0.901</td> <td>   -0.048</td> <td>    0.054</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x413</th>  <td>   -0.1018</td> <td>    0.050</td> <td>   -2.018</td> <td> 0.044</td> <td>   -0.201</td> <td>   -0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x414</th>  <td>   -0.0057</td> <td>    0.033</td> <td>   -0.172</td> <td> 0.864</td> <td>   -0.071</td> <td>    0.060</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x415</th>  <td>   -0.0041</td> <td>    0.038</td> <td>   -0.107</td> <td> 0.915</td> <td>   -0.079</td> <td>    0.071</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x416</th>  <td>   -0.0260</td> <td>    0.033</td> <td>   -0.789</td> <td> 0.430</td> <td>   -0.091</td> <td>    0.039</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x417</th>  <td>    0.0522</td> <td>    0.029</td> <td>    1.790</td> <td> 0.073</td> <td>   -0.005</td> <td>    0.109</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x418</th>  <td>   -0.1136</td> <td>    0.033</td> <td>   -3.421</td> <td> 0.001</td> <td>   -0.179</td> <td>   -0.049</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x419</th>  <td>    0.0029</td> <td>    0.035</td> <td>    0.082</td> <td> 0.935</td> <td>   -0.066</td> <td>    0.072</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x420</th>  <td>    0.0005</td> <td>    0.048</td> <td>    0.011</td> <td> 0.991</td> <td>   -0.093</td> <td>    0.094</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x421</th>  <td>    0.0959</td> <td>    0.040</td> <td>    2.416</td> <td> 0.016</td> <td>    0.018</td> <td>    0.174</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x422</th>  <td>   -0.0003</td> <td>    0.029</td> <td>   -0.011</td> <td> 0.991</td> <td>   -0.056</td> <td>    0.056</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x423</th>  <td>   -0.0106</td> <td>    0.027</td> <td>   -0.390</td> <td> 0.696</td> <td>   -0.064</td> <td>    0.043</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x424</th>  <td>   -0.0213</td> <td>    0.033</td> <td>   -0.649</td> <td> 0.517</td> <td>   -0.086</td> <td>    0.043</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x425</th>  <td>    0.0463</td> <td>    0.026</td> <td>    1.766</td> <td> 0.077</td> <td>   -0.005</td> <td>    0.098</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x426</th>  <td>    0.0010</td> <td>    0.079</td> <td>    0.013</td> <td> 0.989</td> <td>   -0.153</td> <td>    0.156</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x427</th>  <td>   -0.0220</td> <td>    0.043</td> <td>   -0.515</td> <td> 0.607</td> <td>   -0.106</td> <td>    0.062</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x428</th>  <td>    0.0240</td> <td>    0.058</td> <td>    0.416</td> <td> 0.678</td> <td>   -0.089</td> <td>    0.137</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x429</th>  <td>    0.0007</td> <td>    0.042</td> <td>    0.017</td> <td> 0.986</td> <td>   -0.082</td> <td>    0.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x430</th>  <td>    0.0221</td> <td>    0.031</td> <td>    0.702</td> <td> 0.483</td> <td>   -0.040</td> <td>    0.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x431</th>  <td>   -0.0282</td> <td>    0.028</td> <td>   -0.999</td> <td> 0.318</td> <td>   -0.084</td> <td>    0.027</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x432</th>  <td>    0.0663</td> <td>    0.049</td> <td>    1.347</td> <td> 0.178</td> <td>   -0.030</td> <td>    0.163</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x433</th>  <td>   -0.0866</td> <td>    0.040</td> <td>   -2.184</td> <td> 0.029</td> <td>   -0.164</td> <td>   -0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x434</th>  <td>   -0.0074</td> <td>    0.034</td> <td>   -0.217</td> <td> 0.828</td> <td>   -0.075</td> <td>    0.060</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x435</th>  <td>    0.0759</td> <td>    0.039</td> <td>    1.947</td> <td> 0.052</td> <td>   -0.001</td> <td>    0.152</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x436</th>  <td>   -0.0267</td> <td>    0.042</td> <td>   -0.629</td> <td> 0.530</td> <td>   -0.110</td> <td>    0.057</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x437</th>  <td>    0.0022</td> <td>    0.040</td> <td>    0.055</td> <td> 0.956</td> <td>   -0.076</td> <td>    0.081</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x438</th>  <td>   -0.0040</td> <td>    0.028</td> <td>   -0.143</td> <td> 0.886</td> <td>   -0.059</td> <td>    0.051</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x439</th>  <td>    0.0527</td> <td>    0.037</td> <td>    1.441</td> <td> 0.150</td> <td>   -0.019</td> <td>    0.124</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>14442.551</td> <th>  Durbin-Watson:     </th>  <td>   1.896</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>5402600.586</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 7.767</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td>112.725</td>  <th>  Cond. No.          </th>  <td>1.39e+16</td>  \n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.04e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=pd.DataFrame(result.tables[1])\n",
        "result=result.set_index(0)\n",
        "result = result.rename(columns=result.iloc[0])\n",
        "result = result.drop(result.index[0])\n",
        "result.index=df.columns[:-1]\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AjzzlwsNkR0q",
        "outputId": "ac2cb254-48c2-42d0-b038-2a6452bf82cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               coef    std err          t   P>|t|     [0.025  \\\n",
              "학생 ID                        4.3859      2.144      2.045   0.041      0.182   \n",
              "가구 ID                        0.0116      0.014      0.836   0.403     -0.016   \n",
              "교무 ID                     2.785e-10   2.14e-10      1.299   0.194  -1.42e-10   \n",
              "담임 ID                       -0.0268      0.189     -0.142   0.887     -0.396   \n",
              "성별                          -1.1545      1.382     -0.835   0.404     -3.864   \n",
              "...                             ...        ...        ...     ...        ...   \n",
              "(담임평가)진로 취업관련 학부모 상담 경험      0.1449      0.074      1.947   0.052     -0.001   \n",
              "학생 전체 가중치                   -0.0008      0.001     -0.629   0.530     -0.003   \n",
              "진로성숙도                        0.0036      0.065      0.055   0.956     -0.123   \n",
              "다문화수용성                      -0.0054      0.038     -0.143   0.886     -0.079   \n",
              "자기효능감                        0.0776      0.054      1.441   0.150     -0.028   \n",
              "\n",
              "                            0.975]  \n",
              "학생 ID                        8.589  \n",
              "가구 ID                        0.039  \n",
              "교무 ID                     6.99e-10  \n",
              "담임 ID                        0.343  \n",
              "성별                           1.555  \n",
              "...                            ...  \n",
              "(담임평가)진로 취업관련 학부모 상담 경험      0.291  \n",
              "학생 전체 가중치                    0.002  \n",
              "진로성숙도                        0.131  \n",
              "다문화수용성                       0.068  \n",
              "자기효능감                        0.183  \n",
              "\n",
              "[440 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-606886fc-ecf9-4676-9cef-685e3f7cc102\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coef</th>\n",
              "      <th>std err</th>\n",
              "      <th>t</th>\n",
              "      <th>P&gt;|t|</th>\n",
              "      <th>[0.025</th>\n",
              "      <th>0.975]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>학생 ID</th>\n",
              "      <td>4.3859</td>\n",
              "      <td>2.144</td>\n",
              "      <td>2.045</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.182</td>\n",
              "      <td>8.589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>가구 ID</th>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.403</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>0.039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>교무 ID</th>\n",
              "      <td>2.785e-10</td>\n",
              "      <td>2.14e-10</td>\n",
              "      <td>1.299</td>\n",
              "      <td>0.194</td>\n",
              "      <td>-1.42e-10</td>\n",
              "      <td>6.99e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>담임 ID</th>\n",
              "      <td>-0.0268</td>\n",
              "      <td>0.189</td>\n",
              "      <td>-0.142</td>\n",
              "      <td>0.887</td>\n",
              "      <td>-0.396</td>\n",
              "      <td>0.343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>성별</th>\n",
              "      <td>-1.1545</td>\n",
              "      <td>1.382</td>\n",
              "      <td>-0.835</td>\n",
              "      <td>0.404</td>\n",
              "      <td>-3.864</td>\n",
              "      <td>1.555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(담임평가)진로 취업관련 학부모 상담 경험</th>\n",
              "      <td>0.1449</td>\n",
              "      <td>0.074</td>\n",
              "      <td>1.947</td>\n",
              "      <td>0.052</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>학생 전체 가중치</th>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.001</td>\n",
              "      <td>-0.629</td>\n",
              "      <td>0.530</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>0.002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>진로성숙도</th>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.065</td>\n",
              "      <td>0.055</td>\n",
              "      <td>0.956</td>\n",
              "      <td>-0.123</td>\n",
              "      <td>0.131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>다문화수용성</th>\n",
              "      <td>-0.0054</td>\n",
              "      <td>0.038</td>\n",
              "      <td>-0.143</td>\n",
              "      <td>0.886</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>0.068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>자기효능감</th>\n",
              "      <td>0.0776</td>\n",
              "      <td>0.054</td>\n",
              "      <td>1.441</td>\n",
              "      <td>0.150</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>0.183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>440 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-606886fc-ecf9-4676-9cef-685e3f7cc102')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-606886fc-ecf9-4676-9cef-685e3f7cc102 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-606886fc-ecf9-4676-9cef-685e3f7cc102');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    }
  ]
}